/*******************************************************************
  This file has been automatically generated by ispc
  DO NOT EDIT THIS FILE DIRECTLY
 *******************************************************************/

/* Provide Declarations */
#include <stdarg.h>
#include <setjmp.h>
#include <limits.h>
#include <stdlib.h>
#ifdef _MSC_VER
  #define NOMINMAX
  #include <windows.h>
#endif // _MSC_VER
#include <stdlib.h>
#include <stdint.h>
/* get a declaration for alloca */
#ifdef _MSC_VER
  #include <malloc.h>
  #define alloca _alloca
#else
  #include <alloca.h>
#endif

#undef ISPC_FAST_MATH
#include "knc.h"

/* Basic Library Function Declarations */
extern "C" {
int puts(unsigned char *);
unsigned int putchar(unsigned int);
int fflush(void *);
int printf(const unsigned char *, ...);
uint8_t *memcpy(uint8_t *, uint8_t *, uint64_t );
uint8_t *memset(uint8_t *, uint8_t, uint64_t );
void memset_pattern16(void *, const void *, uint64_t );
}

#ifndef __GNUC__  /* Can only support "linkonce" vars with GCC */
#define __attribute__(X)
#endif

#if defined(__GNUC__) && defined(__APPLE_CC__)
#define __EXTERNAL_WEAK__ __attribute__((weak_import))
#elif defined(__GNUC__)
#define __EXTERNAL_WEAK__ __attribute__((weak))
#else
#define __EXTERNAL_WEAK__
#endif

#if defined(__GNUC__) && defined(__APPLE_CC__)
#define __ATTRIBUTE_WEAK__
#elif defined(__GNUC__)
#define __ATTRIBUTE_WEAK__ __attribute__((weak))
#else
#define __ATTRIBUTE_WEAK__
#endif

#if defined(__GNUC__)
#define __HIDDEN__ __attribute__((visibility("hidden")))
#endif

#if (defined(__GNUC__) || defined(__clang__)) && !defined(__INTEL_COMPILER)
#define LLVM_NAN(NanStr)   __builtin_nan(NanStr)   /* Double */
#define LLVM_NANF(NanStr)  __builtin_nanf(NanStr)  /* Float */
#define LLVM_NANS(NanStr)  __builtin_nans(NanStr)  /* Double */
#define LLVM_NANSF(NanStr) __builtin_nansf(NanStr) /* Float */
#define LLVM_INF           __builtin_inf()         /* Double */
#define LLVM_INFF          __builtin_inff()        /* Float */
//#define LLVM_PREFETCH(addr,rw,locality) __builtin_prefetch(addr,rw,locality)
//#define __ATTRIBUTE_CTOR__ __attribute__((constructor))
//#define __ATTRIBUTE_DTOR__ __attribute__((destructor))
#elif defined(_MSC_VER) || defined(__INTEL_COMPILER)
#include <limits>
#define LLVM_NAN(NanStr)   std::numeric_limits<double>::quiet_NaN()
#define LLVM_NANF(NanStr)  std::numeric_limits<float>::quiet_NaN()
#define LLVM_NANS(NanStr)  std::numeric_limits<double>::signaling_NaN()
#define LLVM_NANSF(NanStr) std::numeric_limits<float>::signaling_NaN()
#define LLVM_INF           std::numeric_limits<double>::infinity()
#define LLVM_INFF          std::numeric_limits<float>::infinity()
//#define LLVM_PREFETCH(addr,rw,locality)            /* PREFETCH */
//#define __ATTRIBUTE_CTOR__
//#define __ATTRIBUTE_DTOR__
#else
#error "Not MSVC, clang, or g++?"
#endif

#if (defined(__GNUC__) || defined(__clang__))
#define LLVM_ASM(X) __asm(X)
#endif

#if defined(__clang__) || defined(__INTEL_COMPILER) || (__GNUC__ < 4) /* Old GCCs, or compilers not GCC */ 
#define __builtin_stack_save() 0   /* not implemented */
#define __builtin_stack_restore(X) /* noop */
#endif

#define CODE_FOR_MAIN() /* Any target-specific code for main()*/

#ifndef __cplusplus
typedef unsigned char bool;
#endif


/* Support for floating point constants */
typedef uint64_t ConstantDoubleTy;
typedef uint32_t ConstantFloatTy;
typedef struct { unsigned long long f1; unsigned short f2; unsigned short pad[3]; } ConstantFP80Ty;
typedef struct { uint64_t f1, f2; } ConstantFP128Ty;


/* Global Declarations */


/* Helper union for bitcasts */
typedef union {
  unsigned int Int32;
  unsigned long long Int64;
  float Float;
  double Double;
} llvmBitCastUnion;
/* Structure and array forward declarations */
struct l_unnamed_0;
struct l_array_1;

/* Structure and array contents */
struct l_unnamed_0 {
  static l_unnamed_0 init(float *v0, float *v1, float *v2, float *v3, float *v4, float *v5, uint32_t v6, __vec16_i1 v7) {
    l_unnamed_0 ret;
    ret.field0 = v0;
    ret.field1 = v1;
    ret.field2 = v2;
    ret.field3 = v3;
    ret.field4 = v4;
    ret.field5 = v5;
    ret.field6 = v6;
    ret.field7 = v7;
    return ret;
  }
  float *field0;
  float *field1;
  float *field2;
  float *field3;
  float *field4;
  float *field5;
  uint32_t field6;
  __vec16_i1 field7;
};

struct l_array_1 {
  static l_array_1 init(__vec16_f v0, __vec16_f v1, __vec16_f v2, __vec16_f v3, __vec16_f v4, __vec16_f v5, __vec16_f v6, __vec16_f v7, __vec16_f v8, __vec16_f v9, __vec16_f v10, __vec16_f v11, __vec16_f v12, __vec16_f v13, __vec16_f v14, __vec16_f v15, __vec16_f v16, __vec16_f v17, __vec16_f v18, __vec16_f v19, __vec16_f v20, __vec16_f v21, __vec16_f v22, __vec16_f v23, __vec16_f v24, __vec16_f v25, __vec16_f v26, __vec16_f v27, __vec16_f v28, __vec16_f v29, __vec16_f v30, __vec16_f v31, __vec16_f v32, __vec16_f v33, __vec16_f v34, __vec16_f v35, __vec16_f v36, __vec16_f v37, __vec16_f v38, __vec16_f v39, __vec16_f v40, __vec16_f v41, __vec16_f v42, __vec16_f v43, __vec16_f v44, __vec16_f v45, __vec16_f v46, __vec16_f v47, __vec16_f v48, __vec16_f v49, __vec16_f v50, __vec16_f v51, __vec16_f v52, __vec16_f v53, __vec16_f v54, __vec16_f v55, __vec16_f v56, __vec16_f v57, __vec16_f v58, __vec16_f v59, __vec16_f v60, __vec16_f v61, __vec16_f v62, __vec16_f v63) {
    l_array_1 ret;
    ret.array[0] = v0;
    ret.array[1] = v1;
    ret.array[2] = v2;
    ret.array[3] = v3;
    ret.array[4] = v4;
    ret.array[5] = v5;
    ret.array[6] = v6;
    ret.array[7] = v7;
    ret.array[8] = v8;
    ret.array[9] = v9;
    ret.array[10] = v10;
    ret.array[11] = v11;
    ret.array[12] = v12;
    ret.array[13] = v13;
    ret.array[14] = v14;
    ret.array[15] = v15;
    ret.array[16] = v16;
    ret.array[17] = v17;
    ret.array[18] = v18;
    ret.array[19] = v19;
    ret.array[20] = v20;
    ret.array[21] = v21;
    ret.array[22] = v22;
    ret.array[23] = v23;
    ret.array[24] = v24;
    ret.array[25] = v25;
    ret.array[26] = v26;
    ret.array[27] = v27;
    ret.array[28] = v28;
    ret.array[29] = v29;
    ret.array[30] = v30;
    ret.array[31] = v31;
    ret.array[32] = v32;
    ret.array[33] = v33;
    ret.array[34] = v34;
    ret.array[35] = v35;
    ret.array[36] = v36;
    ret.array[37] = v37;
    ret.array[38] = v38;
    ret.array[39] = v39;
    ret.array[40] = v40;
    ret.array[41] = v41;
    ret.array[42] = v42;
    ret.array[43] = v43;
    ret.array[44] = v44;
    ret.array[45] = v45;
    ret.array[46] = v46;
    ret.array[47] = v47;
    ret.array[48] = v48;
    ret.array[49] = v49;
    ret.array[50] = v50;
    ret.array[51] = v51;
    ret.array[52] = v52;
    ret.array[53] = v53;
    ret.array[54] = v54;
    ret.array[55] = v55;
    ret.array[56] = v56;
    ret.array[57] = v57;
    ret.array[58] = v58;
    ret.array[59] = v59;
    ret.array[60] = v60;
    ret.array[61] = v61;
    ret.array[62] = v62;
    ret.array[63] = v63;
    return ret;
  }
  __vec16_f array[64];
} ;



/* Function Declarations */
extern "C" {
uint8_t *ISPCAlloc(uint8_t **, uint64_t , uint32_t );
void ISPCLaunch(uint8_t **, uint8_t *, uint8_t *, uint32_t );
void ISPCSync(uint8_t *);
void bs_task___un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_uni(l_unnamed_0 *, uint32_t , uint32_t , uint32_t , uint32_t );
void black_scholes_ispc_tasks___un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_uni(float *Sa_, float *Xa_, float *Ta_, float *ra_, float *va_, float *result_, uint32_t count_, __vec16_i1 __mask_);
void black_scholes_ispc___un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_uni(float *Sa_, float *Xa_, float *Ta_, float *ra_, float *va_, float *result_, uint32_t count_, __vec16_i1 __mask_);
void binomial_put_ispc___un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_uni(float *Sa_, float *Xa_, float *Ta_, float *ra_, float *va_, float *result_, uint32_t count_, __vec16_i1 __mask_);
void binomial_task___un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_uni(l_unnamed_0 *, uint32_t , uint32_t , uint32_t , uint32_t );
void binomial_put_ispc_tasks___un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_uni(float *Sa_, float *Xa_, float *Ta_, float *ra_, float *va_, float *result_, uint32_t count_, __vec16_i1 __mask_);
void black_scholes_ispc_tasks(float *Sa_, float *Xa_, float *Ta_, float *ra_, float *va_, float *result_, uint32_t count_);
void black_scholes_ispc(float *Sa_, float *Xa_, float *Ta_, float *ra_, float *va_, float *result_, uint32_t count_);
void binomial_put_ispc(float *Sa_, float *Xa_, float *Ta_, float *ra_, float *va_, float *result_, uint32_t count_);
void binomial_put_ispc_tasks(float *Sa_, float *Xa_, float *Ta_, float *ra_, float *va_, float *result_, uint32_t count_);
}



/* Function Bodies */
template <typename A, typename B> static inline int llvm_fcmp_ord(A X, B Y) { return X == X && Y == Y; }
template <typename A, typename B> static inline int llvm_fcmp_uno(A X, B Y) { return X != X || Y != Y; }
template <typename A, typename B> static inline int llvm_fcmp_ueq(A X, B Y) { return X == Y || llvm_fcmp_uno(X, Y); }
template <typename A, typename B> static inline int llvm_fcmp_une(A X, B Y) { return X != Y; }
template <typename A, typename B> static inline int llvm_fcmp_ult(A X, B Y) { return X <  Y || llvm_fcmp_uno(X, Y); }
template <typename A, typename B> static inline int llvm_fcmp_ugt(A X, B Y) { return X >  Y || llvm_fcmp_uno(X, Y); }
template <typename A, typename B> static inline int llvm_fcmp_ule(A X, B Y) { return X <= Y || llvm_fcmp_uno(X, Y); }
template <typename A, typename B> static inline int llvm_fcmp_uge(A X, B Y) { return X >= Y || llvm_fcmp_uno(X, Y); }
template <typename A, typename B> static inline int llvm_fcmp_oeq(A X, B Y) { return X == Y ; }
template <typename A, typename B> static inline int llvm_fcmp_one(A X, B Y) { return X != Y && llvm_fcmp_ord(X, Y); }
template <typename A, typename B> static inline int llvm_fcmp_olt(A X, B Y) { return X <  Y ; }
template <typename A, typename B> static inline int llvm_fcmp_ogt(A X, B Y) { return X >  Y ; }
template <typename A, typename B> static inline int llvm_fcmp_ole(A X, B Y) { return X <= Y ; }
template <typename A, typename B> static inline int llvm_fcmp_oge(A X, B Y) { return X >= Y ; }
template <typename A> A *Memset(A *ptr, int count, size_t len) { return (A *)memset(ptr, count, len); }

static const int32_t __attribute__ ((aligned(64))) VectorConstant0[] = { 0u, 1u, 2u, 3u, 4u, 5u, 6u, 7u, 8u, 9u, 10u, 11u, 12u, 13u, 14u, 15u,  };

void bs_task___un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_uni(l_unnamed_0 *tmp__1_, uint32_t tmp__2_, uint32_t tmp__3_, uint32_t tmp__4_, uint32_t tmp__5_) {
  float *Sa2_;
  float *Xa4_;
  float *Ta6_;
  float *ra8_;
  float *va10_;
  float *result12_;
  uint32_t count14_;
  uint32_t div_count_load_taskCount_load_;
  uint32_t mul_taskIndex_load_div_count_load_taskCount_load_;
  uint32_t calltmp_2e_i_;
  uint32_t aligned_end_;
  uint8_t *Sa_load_ptr2int_2void_;
  uint8_t *Xa_load_ptr2int_2void_;
  uint8_t *Ta_load_ptr2int_2void_;
  uint8_t *ra_load_ptr2int_2void_;
  uint8_t *va_load_ptr2int_2void_;
  uint8_t *result_load_ptr2int_2void_;
  uint32_t counter_2e_1450_;
  uint32_t counter_2e_1450___PHI;
  uint64_t tmp__6_;
  __vec16_f ptr_masked_load378_;
  __vec16_f ptr380_masked_load382_;
  __vec16_f ptr385_masked_load387_;
  __vec16_f ptr390_masked_load392_;
  __vec16_f ptr395_masked_load397_;
  __vec16_f calltmp_2e_i268_;
  __vec16_f calltmp_2e_i269_;
  __vec16_f div_add_calltmp67_mul_add_r_load_mul_mul_v_load_v_load68__T_load_mul_v_load69_calltmp73_;
  __vec16_f calltmp_2e_i270_;
  __vec16_f sub_d1_load_mul_v_load74_calltmp78_;
  __vec16_f int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i_;
  __vec16_f div__add__mul__L_load_2e_i_;
  __vec16_f mul_k_load_k_load4_2e_i_;
  __vec16_f mul_k2_load_k_load5_2e_i_;
  __vec16_f calltmp_2e_i_2e_i_;
  __vec16_f mul_w_load_mul__calltmp16_2e_i_;
  __vec16_f v1_2e_i_;
  __vec16_f calltmp_2e_i271_;
  __vec16_f int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i277_;
  __vec16_f div__add__mul__L_load_2e_i281_;
  __vec16_f mul_k_load_k_load4_2e_i282_;
  __vec16_f mul_k2_load_k_load5_2e_i283_;
  __vec16_f calltmp_2e_i_2e_i298_;
  __vec16_f mul_w_load_mul__calltmp16_2e_i301_;
  __vec16_f v1_2e_i448_;
  uint32_t new_counter_;
  uint32_t counter_2e_1_2e_lcssa_;
  uint32_t counter_2e_1_2e_lcssa___PHI;
  __vec16_i32 counter_2e_1_2e_lcssa_smear_;
  __vec16_i32 calltmp_2e_i_smear_;
  __vec16_i1 cmp109_;
  uint64_t tmp__7_;
  __vec16_f ptr407_masked_load_;
  __vec16_f ptr413_masked_load_;
  __vec16_f ptr419_masked_load_;
  __vec16_f ptr425_masked_load_;
  __vec16_f ptr431_masked_load_;
  __vec16_f calltmp_2e_i306_;
  __vec16_f calltmp_2e_i307_;
  __vec16_f div_add_calltmp154_mul_add_r_load155_mul_mul_v_load156_v_load157__T_load158_mul_v_load159_calltmp163_;
  __vec16_f calltmp_2e_i308_;
  __vec16_f sub_d1_load165_mul_v_load166_calltmp170_;
  __vec16_f int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i314_;
  __vec16_f div__add__mul__L_load_2e_i318_;
  __vec16_f mul_k_load_k_load4_2e_i319_;
  __vec16_f mul_k2_load_k_load5_2e_i320_;
  __vec16_f calltmp_2e_i_2e_i335_;
  __vec16_f mul_w_load_mul__calltmp16_2e_i338_;
  __vec16_f v1_2e_i446_;
  __vec16_f calltmp_2e_i343_;
  __vec16_f int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i349_;
  __vec16_f div__add__mul__L_load_2e_i353_;
  __vec16_f mul_k_load_k_load4_2e_i354_;
  __vec16_f mul_k2_load_k_load5_2e_i355_;
  __vec16_f calltmp_2e_i_2e_i370_;
  __vec16_f mul_w_load_mul__calltmp16_2e_i373_;
  __vec16_f v1_2e_i444_;

  Sa2_ = *((&tmp__1_->field0));
  Xa4_ = *((&tmp__1_->field1));
  Ta6_ = *((&tmp__1_->field2));
  ra8_ = *((&tmp__1_->field3));
  va10_ = *((&tmp__1_->field4));
  result12_ = *((&tmp__1_->field5));
  count14_ = *((&tmp__1_->field6));
  div_count_load_taskCount_load_ = ((uint32_t )(((uint32_t )count14_) / ((uint32_t )tmp__5_)));
  mul_taskIndex_load_div_count_load_taskCount_load_ = ((uint32_t )(((uint32_t )div_count_load_taskCount_load_) * ((uint32_t )tmp__4_)));
  calltmp_2e_i_ = __min_uniform_int32(count14_, (((uint32_t )(((uint32_t )div_count_load_taskCount_load_) * ((uint32_t )(((uint32_t )(((uint32_t )tmp__4_) + ((uint32_t )1u)))))))));
  aligned_end_ = ((uint32_t )(((uint32_t )calltmp_2e_i_) - ((uint32_t )(((int32_t )(((int32_t )(((uint32_t )(((uint32_t )calltmp_2e_i_) - ((uint32_t )mul_taskIndex_load_div_count_load_taskCount_load_))))) % ((int32_t )16u)))))));
  if ((((int32_t )mul_taskIndex_load_div_count_load_taskCount_load_) < ((int32_t )aligned_end_))) {
    goto foreach_full_body_2e_lr_2e_ph_label;
  } else {
    counter_2e_1_2e_lcssa___PHI = mul_taskIndex_load_div_count_load_taskCount_load_;   /* for PHI node */
    goto partial_inner_all_outer_label;
  }

foreach_full_body_2e_lr_2e_ph_label: {
  Sa_load_ptr2int_2void_ = ((uint8_t *)Sa2_);
  Xa_load_ptr2int_2void_ = ((uint8_t *)Xa4_);
  Ta_load_ptr2int_2void_ = ((uint8_t *)Ta6_);
  ra_load_ptr2int_2void_ = ((uint8_t *)ra8_);
  va_load_ptr2int_2void_ = ((uint8_t *)va10_);
  result_load_ptr2int_2void_ = ((uint8_t *)result12_);
  counter_2e_1450___PHI = mul_taskIndex_load_div_count_load_taskCount_load_;   /* for PHI node */
  goto foreach_full_body_label;

}
  do {     /* Syntactic loop 'foreach_full_body' to make GCC happy */
foreach_full_body_label: {
  counter_2e_1450_ = counter_2e_1450___PHI;
  tmp__6_ = ((int64_t )(int32_t )(counter_2e_1450_ << 2u));
  ptr_masked_load378_ = __load<4>((((__vec16_f (*))((&Sa_load_ptr2int_2void_[((int64_t )tmp__6_)])))));
  ptr380_masked_load382_ = __load<4>((((__vec16_f (*))((&Xa_load_ptr2int_2void_[((int64_t )tmp__6_)])))));
  ptr385_masked_load387_ = __load<4>((((__vec16_f (*))((&Ta_load_ptr2int_2void_[((int64_t )tmp__6_)])))));
  ptr390_masked_load392_ = __load<4>((((__vec16_f (*))((&ra_load_ptr2int_2void_[((int64_t )tmp__6_)])))));
  ptr395_masked_load397_ = __load<4>((((__vec16_f (*))((&va_load_ptr2int_2void_[((int64_t )tmp__6_)])))));
  calltmp_2e_i268_ = __log_varying_float((__div(ptr_masked_load378_, ptr380_masked_load382_)));
  calltmp_2e_i269_ = __sqrt_varying_float(ptr385_masked_load387_);
  div_add_calltmp67_mul_add_r_load_mul_mul_v_load_v_load68__T_load_mul_v_load69_calltmp73_ = __div((__add(calltmp_2e_i268_, (__mul(ptr385_masked_load387_, (__add(ptr390_masked_load392_, (__mul((__mul(ptr395_masked_load397_, ptr395_masked_load397_)), __smear_float<__vec16_f>(0x1p-1))))))))), (__mul(ptr395_masked_load397_, calltmp_2e_i269_)));
  calltmp_2e_i270_ = __sqrt_varying_float(ptr385_masked_load387_);
  sub_d1_load_mul_v_load74_calltmp78_ = __sub(div_add_calltmp67_mul_add_r_load_mul_mul_v_load_v_load68__T_load_mul_v_load69_calltmp73_, (__mul(ptr395_masked_load397_, calltmp_2e_i270_)));
  int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i_ = (__cast_bits(__vec16_f (), (__and(((__cast_bits(__vec16_i32 (), div_add_calltmp67_mul_add_r_load_mul_mul_v_load_v_load68__T_load_mul_v_load69_calltmp73_))), __smear_i32<__vec16_i32>(2147483647u)))));
  div__add__mul__L_load_2e_i_ = __div(__smear_float<__vec16_f>(0x1p+0), (__add((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i_, __smear_float<__vec16_f>(0x1.da6712p-3))), __smear_float<__vec16_f>(0x1p+0))));
  mul_k_load_k_load4_2e_i_ = __mul(div__add__mul__L_load_2e_i_, div__add__mul__L_load_2e_i_);
  mul_k2_load_k_load5_2e_i_ = __mul(div__add__mul__L_load_2e_i_, mul_k_load_k_load4_2e_i_);
  calltmp_2e_i_2e_i_ = __exp_varying_float((__mul((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i_, (__sub(__setzero_float<__vec16_f>(), int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i_)))), __smear_float<__vec16_f>(0x1p-1))));
  mul_w_load_mul__calltmp16_2e_i_ = __mul((__mul(calltmp_2e_i_2e_i_, __smear_float<__vec16_f>(0x1.988454p-2))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i_, mul_k2_load_k_load5_2e_i_)), __smear_float<__vec16_f>(0x1.548cdep+0))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i_, mul_k_load_k_load4_2e_i_)), __smear_float<__vec16_f>(-0x1.d23dd4p+0))), (__add((__sub((__mul(div__add__mul__L_load_2e_i_, __smear_float<__vec16_f>(0x1.470bf4p-2))), (__mul(mul_k_load_k_load4_2e_i_, __smear_float<__vec16_f>(0x1.6d1f0ep-2))))), (__mul(mul_k2_load_k_load5_2e_i_, __smear_float<__vec16_f>(0x1.c80efp+0))))))))));
  v1_2e_i_ = __select((__greater_than_float(div_add_calltmp67_mul_add_r_load_mul_mul_v_load_v_load68__T_load_mul_v_load69_calltmp73_, __setzero_float<__vec16_f>())), (__sub(__smear_float<__vec16_f>(0x1p+0), mul_w_load_mul__calltmp16_2e_i_)), mul_w_load_mul__calltmp16_2e_i_);
  calltmp_2e_i271_ = __exp_varying_float((__mul(ptr385_masked_load387_, (__sub(__setzero_float<__vec16_f>(), ptr390_masked_load392_)))));
  int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i277_ = (__cast_bits(__vec16_f (), (__and(((__cast_bits(__vec16_i32 (), sub_d1_load_mul_v_load74_calltmp78_))), __smear_i32<__vec16_i32>(2147483647u)))));
  div__add__mul__L_load_2e_i281_ = __div(__smear_float<__vec16_f>(0x1p+0), (__add((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i277_, __smear_float<__vec16_f>(0x1.da6712p-3))), __smear_float<__vec16_f>(0x1p+0))));
  mul_k_load_k_load4_2e_i282_ = __mul(div__add__mul__L_load_2e_i281_, div__add__mul__L_load_2e_i281_);
  mul_k2_load_k_load5_2e_i283_ = __mul(div__add__mul__L_load_2e_i281_, mul_k_load_k_load4_2e_i282_);
  calltmp_2e_i_2e_i298_ = __exp_varying_float((__mul((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i277_, (__sub(__setzero_float<__vec16_f>(), int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i277_)))), __smear_float<__vec16_f>(0x1p-1))));
  mul_w_load_mul__calltmp16_2e_i301_ = __mul((__mul(calltmp_2e_i_2e_i298_, __smear_float<__vec16_f>(0x1.988454p-2))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i282_, mul_k2_load_k_load5_2e_i283_)), __smear_float<__vec16_f>(0x1.548cdep+0))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i282_, mul_k_load_k_load4_2e_i282_)), __smear_float<__vec16_f>(-0x1.d23dd4p+0))), (__add((__sub((__mul(div__add__mul__L_load_2e_i281_, __smear_float<__vec16_f>(0x1.470bf4p-2))), (__mul(mul_k_load_k_load4_2e_i282_, __smear_float<__vec16_f>(0x1.6d1f0ep-2))))), (__mul(mul_k2_load_k_load5_2e_i283_, __smear_float<__vec16_f>(0x1.c80efp+0))))))))));
  v1_2e_i448_ = __select((__greater_than_float(sub_d1_load_mul_v_load74_calltmp78_, __setzero_float<__vec16_f>())), (__sub(__smear_float<__vec16_f>(0x1p+0), mul_w_load_mul__calltmp16_2e_i301_)), mul_w_load_mul__calltmp16_2e_i301_);
  __store<4>((((__vec16_f (*))((&result_load_ptr2int_2void_[((int64_t )tmp__6_)])))), (__sub((__mul(ptr_masked_load378_, v1_2e_i_)), (__mul((__mul(ptr380_masked_load382_, calltmp_2e_i271_)), v1_2e_i448_)))));
  new_counter_ = ((uint32_t )(((uint32_t )counter_2e_1450_) + ((uint32_t )16u)));
  if ((((int32_t )new_counter_) < ((int32_t )aligned_end_))) {
    counter_2e_1450___PHI = new_counter_;   /* for PHI node */
    goto foreach_full_body_label;
  } else {
    counter_2e_1_2e_lcssa___PHI = new_counter_;   /* for PHI node */
    goto partial_inner_all_outer_label;
  }

}
  } while (1); /* end of syntactic loop 'foreach_full_body' */
foreach_reset_label: {
  return;
}
partial_inner_all_outer_label: {
  counter_2e_1_2e_lcssa_ = counter_2e_1_2e_lcssa___PHI;
  if ((((int32_t )counter_2e_1_2e_lcssa_) < ((int32_t )calltmp_2e_i_))) {
    goto partial_inner_only_label;
  } else {
    goto foreach_reset_label;
  }

}
partial_inner_only_label: {
  counter_2e_1_2e_lcssa_smear_ = __smear_i32<__vec16_i32>(counter_2e_1_2e_lcssa_);
  calltmp_2e_i_smear_ = __smear_i32<__vec16_i32>(calltmp_2e_i_);
  cmp109_ = __signed_less_than_i32((__add(counter_2e_1_2e_lcssa_smear_, __load<64>((const __vec16_i32  *)(VectorConstant0)))), calltmp_2e_i_smear_);
  tmp__7_ = ((int64_t )(int32_t )(counter_2e_1_2e_lcssa_ << 2u));
  ptr407_masked_load_ = __masked_load_float(((&(((uint8_t *)Sa2_))[((int64_t )tmp__7_)])), cmp109_);
  ptr413_masked_load_ = __masked_load_float(((&(((uint8_t *)Xa4_))[((int64_t )tmp__7_)])), cmp109_);
  ptr419_masked_load_ = __masked_load_float(((&(((uint8_t *)Ta6_))[((int64_t )tmp__7_)])), cmp109_);
  ptr425_masked_load_ = __masked_load_float(((&(((uint8_t *)ra8_))[((int64_t )tmp__7_)])), cmp109_);
  ptr431_masked_load_ = __masked_load_float(((&(((uint8_t *)va10_))[((int64_t )tmp__7_)])), cmp109_);
  calltmp_2e_i306_ = __log_varying_float((__div(ptr407_masked_load_, ptr413_masked_load_)));
  calltmp_2e_i307_ = __sqrt_varying_float(ptr419_masked_load_);
  div_add_calltmp154_mul_add_r_load155_mul_mul_v_load156_v_load157__T_load158_mul_v_load159_calltmp163_ = __div((__add(calltmp_2e_i306_, (__mul(ptr419_masked_load_, (__add(ptr425_masked_load_, (__mul((__mul(ptr431_masked_load_, ptr431_masked_load_)), __smear_float<__vec16_f>(0x1p-1))))))))), (__mul(ptr431_masked_load_, calltmp_2e_i307_)));
  calltmp_2e_i308_ = __sqrt_varying_float(ptr419_masked_load_);
  sub_d1_load165_mul_v_load166_calltmp170_ = __sub(div_add_calltmp154_mul_add_r_load155_mul_mul_v_load156_v_load157__T_load158_mul_v_load159_calltmp163_, (__mul(ptr431_masked_load_, calltmp_2e_i308_)));
  int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i314_ = (__cast_bits(__vec16_f (), (__and(((__cast_bits(__vec16_i32 (), div_add_calltmp154_mul_add_r_load155_mul_mul_v_load156_v_load157__T_load158_mul_v_load159_calltmp163_))), __smear_i32<__vec16_i32>(2147483647u)))));
  div__add__mul__L_load_2e_i318_ = __div(__smear_float<__vec16_f>(0x1p+0), (__add((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i314_, __smear_float<__vec16_f>(0x1.da6712p-3))), __smear_float<__vec16_f>(0x1p+0))));
  mul_k_load_k_load4_2e_i319_ = __mul(div__add__mul__L_load_2e_i318_, div__add__mul__L_load_2e_i318_);
  mul_k2_load_k_load5_2e_i320_ = __mul(div__add__mul__L_load_2e_i318_, mul_k_load_k_load4_2e_i319_);
  calltmp_2e_i_2e_i335_ = __exp_varying_float((__mul((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i314_, (__sub(__setzero_float<__vec16_f>(), int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i314_)))), __smear_float<__vec16_f>(0x1p-1))));
  mul_w_load_mul__calltmp16_2e_i338_ = __mul((__mul(calltmp_2e_i_2e_i335_, __smear_float<__vec16_f>(0x1.988454p-2))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i319_, mul_k2_load_k_load5_2e_i320_)), __smear_float<__vec16_f>(0x1.548cdep+0))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i319_, mul_k_load_k_load4_2e_i319_)), __smear_float<__vec16_f>(-0x1.d23dd4p+0))), (__add((__sub((__mul(div__add__mul__L_load_2e_i318_, __smear_float<__vec16_f>(0x1.470bf4p-2))), (__mul(mul_k_load_k_load4_2e_i319_, __smear_float<__vec16_f>(0x1.6d1f0ep-2))))), (__mul(mul_k2_load_k_load5_2e_i320_, __smear_float<__vec16_f>(0x1.c80efp+0))))))))));
  v1_2e_i446_ = __select((__greater_than_float(div_add_calltmp154_mul_add_r_load155_mul_mul_v_load156_v_load157__T_load158_mul_v_load159_calltmp163_, __setzero_float<__vec16_f>())), (__sub(__smear_float<__vec16_f>(0x1p+0), mul_w_load_mul__calltmp16_2e_i338_)), mul_w_load_mul__calltmp16_2e_i338_);
  calltmp_2e_i343_ = __exp_varying_float((__mul(ptr419_masked_load_, (__sub(__setzero_float<__vec16_f>(), ptr425_masked_load_)))));
  int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i349_ = (__cast_bits(__vec16_f (), (__and(((__cast_bits(__vec16_i32 (), sub_d1_load165_mul_v_load166_calltmp170_))), __smear_i32<__vec16_i32>(2147483647u)))));
  div__add__mul__L_load_2e_i353_ = __div(__smear_float<__vec16_f>(0x1p+0), (__add((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i349_, __smear_float<__vec16_f>(0x1.da6712p-3))), __smear_float<__vec16_f>(0x1p+0))));
  mul_k_load_k_load4_2e_i354_ = __mul(div__add__mul__L_load_2e_i353_, div__add__mul__L_load_2e_i353_);
  mul_k2_load_k_load5_2e_i355_ = __mul(div__add__mul__L_load_2e_i353_, mul_k_load_k_load4_2e_i354_);
  calltmp_2e_i_2e_i370_ = __exp_varying_float((__mul((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i349_, (__sub(__setzero_float<__vec16_f>(), int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i349_)))), __smear_float<__vec16_f>(0x1p-1))));
  mul_w_load_mul__calltmp16_2e_i373_ = __mul((__mul(calltmp_2e_i_2e_i370_, __smear_float<__vec16_f>(0x1.988454p-2))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i354_, mul_k2_load_k_load5_2e_i355_)), __smear_float<__vec16_f>(0x1.548cdep+0))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i354_, mul_k_load_k_load4_2e_i354_)), __smear_float<__vec16_f>(-0x1.d23dd4p+0))), (__add((__sub((__mul(div__add__mul__L_load_2e_i353_, __smear_float<__vec16_f>(0x1.470bf4p-2))), (__mul(mul_k_load_k_load4_2e_i354_, __smear_float<__vec16_f>(0x1.6d1f0ep-2))))), (__mul(mul_k2_load_k_load5_2e_i355_, __smear_float<__vec16_f>(0x1.c80efp+0))))))))));
  v1_2e_i444_ = __select((__greater_than_float(sub_d1_load165_mul_v_load166_calltmp170_, __setzero_float<__vec16_f>())), (__sub(__smear_float<__vec16_f>(0x1p+0), mul_w_load_mul__calltmp16_2e_i373_)), mul_w_load_mul__calltmp16_2e_i373_);
  __masked_store_float((((__vec16_f (*))((&(((uint8_t *)result12_))[((int64_t )tmp__7_)])))), (__sub((__mul(ptr407_masked_load_, v1_2e_i446_)), (__mul((__mul(ptr413_masked_load_, calltmp_2e_i343_)), v1_2e_i444_)))), cmp109_);
  goto foreach_reset_label;

}
}



void black_scholes_ispc_tasks___un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_uni(float *Sa_, float *Xa_, float *Ta_, float *ra_, float *va_, float *result_, uint32_t count_, __vec16_i1 __mask_) {
  uint8_t *launch_group_handle_;    /* Address-exposed local */
  uint32_t calltmp_2e_i_;
  uint8_t *args_ptr_;
  uint8_t *launch_group_handle_load_;

  *(&launch_group_handle_) = ((uint8_t *)/*NULL*/0);
  calltmp_2e_i_ = __max_uniform_int32(64u, (((int32_t )(((int32_t )count_) / ((int32_t )16384u)))));
  args_ptr_ = ISPCAlloc((&launch_group_handle_), 56ull, 64u);
  *(((float **)args_ptr_)) = Sa_;
  *(((float **)((&args_ptr_[((int64_t )8ull)])))) = Xa_;
  *(((float **)((&args_ptr_[((int64_t )16ull)])))) = Ta_;
  *(((float **)((&args_ptr_[((int64_t )24ull)])))) = ra_;
  *(((float **)((&args_ptr_[((int64_t )32ull)])))) = va_;
  *(((float **)((&args_ptr_[((int64_t )40ull)])))) = result_;
  *(((uint32_t *)((&args_ptr_[((int64_t )48ull)])))) = count_;
  __store<2>((((__vec16_i1 (*))((&args_ptr_[((int64_t )52ull)])))), __mask_);
  ISPCLaunch((&launch_group_handle_), ((uint8_t *)bs_task___un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_uni), args_ptr_, calltmp_2e_i_);
  launch_group_handle_load_ = *(&launch_group_handle_);
  if ((launch_group_handle_load_ == ((uint8_t *)/*NULL*/0))) {
    goto post_sync_label;
  } else {
    goto call_sync_label;
  }

call_sync_label: {
  ISPCSync(launch_group_handle_load_);
  *(&launch_group_handle_) = ((uint8_t *)/*NULL*/0);
  goto post_sync_label;

}
post_sync_label: {
  return;
}
}


static const int32_t __attribute__ ((aligned(64))) VectorConstant1[] = { 0u, 1u, 2u, 3u, 4u, 5u, 6u, 7u, 8u, 9u, 10u, 11u, 12u, 13u, 14u, 15u,  };

void black_scholes_ispc___un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_uni(float *Sa_, float *Xa_, float *Ta_, float *ra_, float *va_, float *result_, uint32_t count_, __vec16_i1 __mask_) {
  uint32_t aligned_end_;
  uint8_t *Sa_load_ptr2int_2void_;
  uint8_t *Xa_load_ptr2int_2void_;
  uint8_t *Ta_load_ptr2int_2void_;
  uint8_t *ra_load_ptr2int_2void_;
  uint8_t *va_load_ptr2int_2void_;
  uint8_t *result_load_ptr2int_2void_;
  uint32_t counter_2e_1435_;
  uint32_t counter_2e_1435___PHI;
  uint64_t tmp__8_;
  __vec16_f ptr_masked_load363_;
  __vec16_f ptr365_masked_load367_;
  __vec16_f ptr370_masked_load372_;
  __vec16_f ptr375_masked_load377_;
  __vec16_f ptr380_masked_load382_;
  __vec16_f calltmp_2e_i_;
  __vec16_f calltmp_2e_i254_;
  __vec16_f div_add_calltmp_mul_add_r_load_mul_mul_v_load_v_load54__T_load_mul_v_load55_calltmp59_;
  __vec16_f calltmp_2e_i255_;
  __vec16_f sub_d1_load_mul_v_load60_calltmp64_;
  __vec16_f int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i_;
  __vec16_f div__add__mul__L_load_2e_i_;
  __vec16_f mul_k_load_k_load4_2e_i_;
  __vec16_f mul_k2_load_k_load5_2e_i_;
  __vec16_f calltmp_2e_i_2e_i_;
  __vec16_f mul_w_load_mul__calltmp16_2e_i_;
  __vec16_f v1_2e_i_;
  __vec16_f calltmp_2e_i256_;
  __vec16_f int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i262_;
  __vec16_f div__add__mul__L_load_2e_i266_;
  __vec16_f mul_k_load_k_load4_2e_i267_;
  __vec16_f mul_k2_load_k_load5_2e_i268_;
  __vec16_f calltmp_2e_i_2e_i283_;
  __vec16_f mul_w_load_mul__calltmp16_2e_i286_;
  __vec16_f v1_2e_i433_;
  uint32_t new_counter_;
  uint32_t counter_2e_1_2e_lcssa_;
  uint32_t counter_2e_1_2e_lcssa___PHI;
  __vec16_i32 counter_2e_1_2e_lcssa_smear_;
  __vec16_i32 count_smear_;
  __vec16_i1 cmp95_;
  uint64_t tmp__9_;
  __vec16_f ptr392_masked_load_;
  __vec16_f ptr398_masked_load_;
  __vec16_f ptr404_masked_load_;
  __vec16_f ptr410_masked_load_;
  __vec16_f ptr416_masked_load_;
  __vec16_f calltmp_2e_i291_;
  __vec16_f calltmp_2e_i292_;
  __vec16_f div_add_calltmp140_mul_add_r_load141_mul_mul_v_load142_v_load143__T_load144_mul_v_load145_calltmp149_;
  __vec16_f calltmp_2e_i293_;
  __vec16_f sub_d1_load151_mul_v_load152_calltmp156_;
  __vec16_f int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i299_;
  __vec16_f div__add__mul__L_load_2e_i303_;
  __vec16_f mul_k_load_k_load4_2e_i304_;
  __vec16_f mul_k2_load_k_load5_2e_i305_;
  __vec16_f calltmp_2e_i_2e_i320_;
  __vec16_f mul_w_load_mul__calltmp16_2e_i323_;
  __vec16_f v1_2e_i431_;
  __vec16_f calltmp_2e_i328_;
  __vec16_f int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i334_;
  __vec16_f div__add__mul__L_load_2e_i338_;
  __vec16_f mul_k_load_k_load4_2e_i339_;
  __vec16_f mul_k2_load_k_load5_2e_i340_;
  __vec16_f calltmp_2e_i_2e_i355_;
  __vec16_f mul_w_load_mul__calltmp16_2e_i358_;
  __vec16_f v1_2e_i429_;

  aligned_end_ = ((uint32_t )(((uint32_t )count_) - ((uint32_t )(((int32_t )(((int32_t )count_) % ((int32_t )16u)))))));
  if ((((int32_t )aligned_end_) > ((int32_t )0u))) {
    goto foreach_full_body_2e_lr_2e_ph_label;
  } else {
    counter_2e_1_2e_lcssa___PHI = 0u;   /* for PHI node */
    goto partial_inner_all_outer_label;
  }

foreach_full_body_2e_lr_2e_ph_label: {
  Sa_load_ptr2int_2void_ = ((uint8_t *)Sa_);
  Xa_load_ptr2int_2void_ = ((uint8_t *)Xa_);
  Ta_load_ptr2int_2void_ = ((uint8_t *)Ta_);
  ra_load_ptr2int_2void_ = ((uint8_t *)ra_);
  va_load_ptr2int_2void_ = ((uint8_t *)va_);
  result_load_ptr2int_2void_ = ((uint8_t *)result_);
  counter_2e_1435___PHI = 0u;   /* for PHI node */
  goto foreach_full_body_label;

}
  do {     /* Syntactic loop 'foreach_full_body' to make GCC happy */
foreach_full_body_label: {
  counter_2e_1435_ = counter_2e_1435___PHI;
  tmp__8_ = ((int64_t )(int32_t )(counter_2e_1435_ << 2u));
  ptr_masked_load363_ = __load<4>((((__vec16_f (*))((&Sa_load_ptr2int_2void_[((int64_t )tmp__8_)])))));
  ptr365_masked_load367_ = __load<4>((((__vec16_f (*))((&Xa_load_ptr2int_2void_[((int64_t )tmp__8_)])))));
  ptr370_masked_load372_ = __load<4>((((__vec16_f (*))((&Ta_load_ptr2int_2void_[((int64_t )tmp__8_)])))));
  ptr375_masked_load377_ = __load<4>((((__vec16_f (*))((&ra_load_ptr2int_2void_[((int64_t )tmp__8_)])))));
  ptr380_masked_load382_ = __load<4>((((__vec16_f (*))((&va_load_ptr2int_2void_[((int64_t )tmp__8_)])))));
  calltmp_2e_i_ = __log_varying_float((__div(ptr_masked_load363_, ptr365_masked_load367_)));
  calltmp_2e_i254_ = __sqrt_varying_float(ptr370_masked_load372_);
  div_add_calltmp_mul_add_r_load_mul_mul_v_load_v_load54__T_load_mul_v_load55_calltmp59_ = __div((__add(calltmp_2e_i_, (__mul(ptr370_masked_load372_, (__add(ptr375_masked_load377_, (__mul((__mul(ptr380_masked_load382_, ptr380_masked_load382_)), __smear_float<__vec16_f>(0x1p-1))))))))), (__mul(ptr380_masked_load382_, calltmp_2e_i254_)));
  calltmp_2e_i255_ = __sqrt_varying_float(ptr370_masked_load372_);
  sub_d1_load_mul_v_load60_calltmp64_ = __sub(div_add_calltmp_mul_add_r_load_mul_mul_v_load_v_load54__T_load_mul_v_load55_calltmp59_, (__mul(ptr380_masked_load382_, calltmp_2e_i255_)));
  int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i_ = (__cast_bits(__vec16_f (), (__and(((__cast_bits(__vec16_i32 (), div_add_calltmp_mul_add_r_load_mul_mul_v_load_v_load54__T_load_mul_v_load55_calltmp59_))), __smear_i32<__vec16_i32>(2147483647u)))));
  div__add__mul__L_load_2e_i_ = __div(__smear_float<__vec16_f>(0x1p+0), (__add((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i_, __smear_float<__vec16_f>(0x1.da6712p-3))), __smear_float<__vec16_f>(0x1p+0))));
  mul_k_load_k_load4_2e_i_ = __mul(div__add__mul__L_load_2e_i_, div__add__mul__L_load_2e_i_);
  mul_k2_load_k_load5_2e_i_ = __mul(div__add__mul__L_load_2e_i_, mul_k_load_k_load4_2e_i_);
  calltmp_2e_i_2e_i_ = __exp_varying_float((__mul((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i_, (__sub(__setzero_float<__vec16_f>(), int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i_)))), __smear_float<__vec16_f>(0x1p-1))));
  mul_w_load_mul__calltmp16_2e_i_ = __mul((__mul(calltmp_2e_i_2e_i_, __smear_float<__vec16_f>(0x1.988454p-2))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i_, mul_k2_load_k_load5_2e_i_)), __smear_float<__vec16_f>(0x1.548cdep+0))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i_, mul_k_load_k_load4_2e_i_)), __smear_float<__vec16_f>(-0x1.d23dd4p+0))), (__add((__sub((__mul(div__add__mul__L_load_2e_i_, __smear_float<__vec16_f>(0x1.470bf4p-2))), (__mul(mul_k_load_k_load4_2e_i_, __smear_float<__vec16_f>(0x1.6d1f0ep-2))))), (__mul(mul_k2_load_k_load5_2e_i_, __smear_float<__vec16_f>(0x1.c80efp+0))))))))));
  v1_2e_i_ = __select((__greater_than_float(div_add_calltmp_mul_add_r_load_mul_mul_v_load_v_load54__T_load_mul_v_load55_calltmp59_, __setzero_float<__vec16_f>())), (__sub(__smear_float<__vec16_f>(0x1p+0), mul_w_load_mul__calltmp16_2e_i_)), mul_w_load_mul__calltmp16_2e_i_);
  calltmp_2e_i256_ = __exp_varying_float((__mul(ptr370_masked_load372_, (__sub(__setzero_float<__vec16_f>(), ptr375_masked_load377_)))));
  int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i262_ = (__cast_bits(__vec16_f (), (__and(((__cast_bits(__vec16_i32 (), sub_d1_load_mul_v_load60_calltmp64_))), __smear_i32<__vec16_i32>(2147483647u)))));
  div__add__mul__L_load_2e_i266_ = __div(__smear_float<__vec16_f>(0x1p+0), (__add((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i262_, __smear_float<__vec16_f>(0x1.da6712p-3))), __smear_float<__vec16_f>(0x1p+0))));
  mul_k_load_k_load4_2e_i267_ = __mul(div__add__mul__L_load_2e_i266_, div__add__mul__L_load_2e_i266_);
  mul_k2_load_k_load5_2e_i268_ = __mul(div__add__mul__L_load_2e_i266_, mul_k_load_k_load4_2e_i267_);
  calltmp_2e_i_2e_i283_ = __exp_varying_float((__mul((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i262_, (__sub(__setzero_float<__vec16_f>(), int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i262_)))), __smear_float<__vec16_f>(0x1p-1))));
  mul_w_load_mul__calltmp16_2e_i286_ = __mul((__mul(calltmp_2e_i_2e_i283_, __smear_float<__vec16_f>(0x1.988454p-2))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i267_, mul_k2_load_k_load5_2e_i268_)), __smear_float<__vec16_f>(0x1.548cdep+0))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i267_, mul_k_load_k_load4_2e_i267_)), __smear_float<__vec16_f>(-0x1.d23dd4p+0))), (__add((__sub((__mul(div__add__mul__L_load_2e_i266_, __smear_float<__vec16_f>(0x1.470bf4p-2))), (__mul(mul_k_load_k_load4_2e_i267_, __smear_float<__vec16_f>(0x1.6d1f0ep-2))))), (__mul(mul_k2_load_k_load5_2e_i268_, __smear_float<__vec16_f>(0x1.c80efp+0))))))))));
  v1_2e_i433_ = __select((__greater_than_float(sub_d1_load_mul_v_load60_calltmp64_, __setzero_float<__vec16_f>())), (__sub(__smear_float<__vec16_f>(0x1p+0), mul_w_load_mul__calltmp16_2e_i286_)), mul_w_load_mul__calltmp16_2e_i286_);
  __store<4>((((__vec16_f (*))((&result_load_ptr2int_2void_[((int64_t )tmp__8_)])))), (__sub((__mul(ptr_masked_load363_, v1_2e_i_)), (__mul((__mul(ptr365_masked_load367_, calltmp_2e_i256_)), v1_2e_i433_)))));
  new_counter_ = ((uint32_t )(((uint32_t )counter_2e_1435_) + ((uint32_t )16u)));
  if ((((int32_t )new_counter_) < ((int32_t )aligned_end_))) {
    counter_2e_1435___PHI = new_counter_;   /* for PHI node */
    goto foreach_full_body_label;
  } else {
    counter_2e_1_2e_lcssa___PHI = new_counter_;   /* for PHI node */
    goto partial_inner_all_outer_label;
  }

}
  } while (1); /* end of syntactic loop 'foreach_full_body' */
foreach_reset_label: {
  return;
}
partial_inner_all_outer_label: {
  counter_2e_1_2e_lcssa_ = counter_2e_1_2e_lcssa___PHI;
  if ((((int32_t )counter_2e_1_2e_lcssa_) < ((int32_t )count_))) {
    goto partial_inner_only_label;
  } else {
    goto foreach_reset_label;
  }

}
partial_inner_only_label: {
  counter_2e_1_2e_lcssa_smear_ = __smear_i32<__vec16_i32>(counter_2e_1_2e_lcssa_);
  count_smear_ = __smear_i32<__vec16_i32>(count_);
  cmp95_ = __signed_less_than_i32((__add(counter_2e_1_2e_lcssa_smear_, __load<64>((const __vec16_i32  *)(VectorConstant1)))), count_smear_);
  tmp__9_ = ((int64_t )(int32_t )(counter_2e_1_2e_lcssa_ << 2u));
  ptr392_masked_load_ = __masked_load_float(((&(((uint8_t *)Sa_))[((int64_t )tmp__9_)])), cmp95_);
  ptr398_masked_load_ = __masked_load_float(((&(((uint8_t *)Xa_))[((int64_t )tmp__9_)])), cmp95_);
  ptr404_masked_load_ = __masked_load_float(((&(((uint8_t *)Ta_))[((int64_t )tmp__9_)])), cmp95_);
  ptr410_masked_load_ = __masked_load_float(((&(((uint8_t *)ra_))[((int64_t )tmp__9_)])), cmp95_);
  ptr416_masked_load_ = __masked_load_float(((&(((uint8_t *)va_))[((int64_t )tmp__9_)])), cmp95_);
  calltmp_2e_i291_ = __log_varying_float((__div(ptr392_masked_load_, ptr398_masked_load_)));
  calltmp_2e_i292_ = __sqrt_varying_float(ptr404_masked_load_);
  div_add_calltmp140_mul_add_r_load141_mul_mul_v_load142_v_load143__T_load144_mul_v_load145_calltmp149_ = __div((__add(calltmp_2e_i291_, (__mul(ptr404_masked_load_, (__add(ptr410_masked_load_, (__mul((__mul(ptr416_masked_load_, ptr416_masked_load_)), __smear_float<__vec16_f>(0x1p-1))))))))), (__mul(ptr416_masked_load_, calltmp_2e_i292_)));
  calltmp_2e_i293_ = __sqrt_varying_float(ptr404_masked_load_);
  sub_d1_load151_mul_v_load152_calltmp156_ = __sub(div_add_calltmp140_mul_add_r_load141_mul_mul_v_load142_v_load143__T_load144_mul_v_load145_calltmp149_, (__mul(ptr416_masked_load_, calltmp_2e_i293_)));
  int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i299_ = (__cast_bits(__vec16_f (), (__and(((__cast_bits(__vec16_i32 (), div_add_calltmp140_mul_add_r_load141_mul_mul_v_load142_v_load143__T_load144_mul_v_load145_calltmp149_))), __smear_i32<__vec16_i32>(2147483647u)))));
  div__add__mul__L_load_2e_i303_ = __div(__smear_float<__vec16_f>(0x1p+0), (__add((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i299_, __smear_float<__vec16_f>(0x1.da6712p-3))), __smear_float<__vec16_f>(0x1p+0))));
  mul_k_load_k_load4_2e_i304_ = __mul(div__add__mul__L_load_2e_i303_, div__add__mul__L_load_2e_i303_);
  mul_k2_load_k_load5_2e_i305_ = __mul(div__add__mul__L_load_2e_i303_, mul_k_load_k_load4_2e_i304_);
  calltmp_2e_i_2e_i320_ = __exp_varying_float((__mul((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i299_, (__sub(__setzero_float<__vec16_f>(), int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i299_)))), __smear_float<__vec16_f>(0x1p-1))));
  mul_w_load_mul__calltmp16_2e_i323_ = __mul((__mul(calltmp_2e_i_2e_i320_, __smear_float<__vec16_f>(0x1.988454p-2))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i304_, mul_k2_load_k_load5_2e_i305_)), __smear_float<__vec16_f>(0x1.548cdep+0))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i304_, mul_k_load_k_load4_2e_i304_)), __smear_float<__vec16_f>(-0x1.d23dd4p+0))), (__add((__sub((__mul(div__add__mul__L_load_2e_i303_, __smear_float<__vec16_f>(0x1.470bf4p-2))), (__mul(mul_k_load_k_load4_2e_i304_, __smear_float<__vec16_f>(0x1.6d1f0ep-2))))), (__mul(mul_k2_load_k_load5_2e_i305_, __smear_float<__vec16_f>(0x1.c80efp+0))))))))));
  v1_2e_i431_ = __select((__greater_than_float(div_add_calltmp140_mul_add_r_load141_mul_mul_v_load142_v_load143__T_load144_mul_v_load145_calltmp149_, __setzero_float<__vec16_f>())), (__sub(__smear_float<__vec16_f>(0x1p+0), mul_w_load_mul__calltmp16_2e_i323_)), mul_w_load_mul__calltmp16_2e_i323_);
  calltmp_2e_i328_ = __exp_varying_float((__mul(ptr404_masked_load_, (__sub(__setzero_float<__vec16_f>(), ptr410_masked_load_)))));
  int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i334_ = (__cast_bits(__vec16_f (), (__and(((__cast_bits(__vec16_i32 (), sub_d1_load151_mul_v_load152_calltmp156_))), __smear_i32<__vec16_i32>(2147483647u)))));
  div__add__mul__L_load_2e_i338_ = __div(__smear_float<__vec16_f>(0x1p+0), (__add((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i334_, __smear_float<__vec16_f>(0x1.da6712p-3))), __smear_float<__vec16_f>(0x1p+0))));
  mul_k_load_k_load4_2e_i339_ = __mul(div__add__mul__L_load_2e_i338_, div__add__mul__L_load_2e_i338_);
  mul_k2_load_k_load5_2e_i340_ = __mul(div__add__mul__L_load_2e_i338_, mul_k_load_k_load4_2e_i339_);
  calltmp_2e_i_2e_i355_ = __exp_varying_float((__mul((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i334_, (__sub(__setzero_float<__vec16_f>(), int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i334_)))), __smear_float<__vec16_f>(0x1p-1))));
  mul_w_load_mul__calltmp16_2e_i358_ = __mul((__mul(calltmp_2e_i_2e_i355_, __smear_float<__vec16_f>(0x1.988454p-2))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i339_, mul_k2_load_k_load5_2e_i340_)), __smear_float<__vec16_f>(0x1.548cdep+0))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i339_, mul_k_load_k_load4_2e_i339_)), __smear_float<__vec16_f>(-0x1.d23dd4p+0))), (__add((__sub((__mul(div__add__mul__L_load_2e_i338_, __smear_float<__vec16_f>(0x1.470bf4p-2))), (__mul(mul_k_load_k_load4_2e_i339_, __smear_float<__vec16_f>(0x1.6d1f0ep-2))))), (__mul(mul_k2_load_k_load5_2e_i340_, __smear_float<__vec16_f>(0x1.c80efp+0))))))))));
  v1_2e_i429_ = __select((__greater_than_float(sub_d1_load151_mul_v_load152_calltmp156_, __setzero_float<__vec16_f>())), (__sub(__smear_float<__vec16_f>(0x1p+0), mul_w_load_mul__calltmp16_2e_i358_)), mul_w_load_mul__calltmp16_2e_i358_);
  __masked_store_float((((__vec16_f (*))((&(((uint8_t *)result_))[((int64_t )tmp__9_)])))), (__sub((__mul(ptr392_masked_load_, v1_2e_i431_)), (__mul((__mul(ptr398_masked_load_, calltmp_2e_i328_)), v1_2e_i429_)))), cmp95_);
  goto foreach_reset_label;

}
}


static const int32_t __attribute__ ((aligned(64))) VectorConstant2[] = { 0u, 1u, 2u, 3u, 4u, 5u, 6u, 7u, 8u, 9u, 10u, 11u, 12u, 13u, 14u, 15u,  };

void binomial_put_ispc___un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_uni(float *Sa_, float *Xa_, float *Ta_, float *ra_, float *va_, float *result_, uint32_t count_, __vec16_i1 __mask_) {
  l_array_1 V_2e_i_;    /* Address-exposed local */
  uint32_t aligned_end_;
  uint8_t *Sa_load_ptr2int_2void_;
  uint8_t *Xa_load_ptr2int_2void_;
  uint8_t *Ta_load_ptr2int_2void_;
  uint8_t *ra_load_ptr2int_2void_;
  uint8_t *va_load_ptr2int_2void_;
  uint8_t *tmp__10_;
  __vec16_f (*V_offset59_2e_i_);
  uint8_t *result_load_ptr2int_2void_;
  uint32_t counter_2e_1324_;
  uint32_t counter_2e_1324___PHI;
  uint64_t tmp__11_;
  __vec16_f ptr_masked_load256_;
  __vec16_f ptr258_masked_load260_;
  __vec16_f ptr263_masked_load265_;
  __vec16_f ptr268_masked_load270_;
  __vec16_f ptr273_masked_load275_;
  __vec16_f div_T_load__2e_i_;
  __vec16_f calltmp_2e_i_2e_i_;
  __vec16_f calltmp_2e_i1_2e_i_;
  __vec16_f div__u_load_2e_i_;
  __vec16_f calltmp_2e_i2_2e_i_;
  __vec16_f sub_u_load15_d_load16_2e_i_;
  uint64_t indvars_2e_iv333_;
  uint64_t indvars_2e_iv333___PHI;
  __vec16_f sub_mul__j_load21__to_float_2e_i_smear_;
  __vec16_f calltmp_2e_i3_2e_i_;
  __vec16_f calltmp_2e_i4_2e_i_;
  uint64_t indvars_2e_iv_2e_next334_;
  __vec16_f div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i_;
  __vec16_f sub__Pu_load_2e_i_;
  uint32_t indvars_2e_iv341_;
  uint32_t indvars_2e_iv341___PHI;
  uint64_t indvars_2e_iv339_;
  uint64_t indvars_2e_iv339___PHI;
  __vec16_f (*V_offset48_2e_i_);
  __vec16_f V_offset50_load_2e_i_;
  uint64_t indvars_2e_iv_2e_next340_;
  __vec16_f V_offset54_load_2e_i_;
  uint32_t indvars_2e_iv_2e_next342_;
  __vec16_f V_offset59_load_2e_i_;
  uint32_t new_counter_;
  __vec16_f div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i211_;
  __vec16_f sub__Pu_load_2e_i239_;
  uint64_t indvars_2e_iv327_;
  uint64_t indvars_2e_iv327___PHI;
  __vec16_f sub_mul__j_load21__to_float_2e_i217_smear_;
  __vec16_f calltmp_2e_i3_2e_i220_;
  __vec16_f calltmp_2e_i4_2e_i225_;
  uint64_t indvars_2e_iv_2e_next328_;
  uint32_t indvars_2e_iv325_;
  uint32_t indvars_2e_iv325___PHI;
  uint64_t indvars_2e_iv_;
  uint64_t indvars_2e_iv___PHI;
  __vec16_f (*V_offset48_2e_i238_);
  __vec16_f V_offset50_load_2e_i242_;
  uint64_t indvars_2e_iv_2e_next_;
  __vec16_f V_offset54_load_2e_i247_;
  uint32_t indvars_2e_iv_2e_next326_;
  __vec16_f V_offset59_load_2e_i232_;
  uint32_t counter_2e_1_2e_lcssa_;
  uint32_t counter_2e_1_2e_lcssa___PHI;
  __vec16_i32 counter_2e_1_2e_lcssa_smear_;
  __vec16_i32 count_smear_;
  __vec16_i1 cmp70_;
  uint64_t tmp__12_;
  __vec16_f ptr282_masked_load_;
  __vec16_f ptr288_masked_load_;
  __vec16_f ptr294_masked_load_;
  __vec16_f ptr300_masked_load_;
  __vec16_f ptr306_masked_load_;
  uint8_t *tmp__13_;
  __vec16_f div_T_load__2e_i202_;
  __vec16_f calltmp_2e_i_2e_i203_;
  __vec16_f calltmp_2e_i1_2e_i205_;
  __vec16_f div__u_load_2e_i206_;
  __vec16_f calltmp_2e_i2_2e_i208_;
  __vec16_f sub_u_load15_d_load16_2e_i210_;

  aligned_end_ = ((uint32_t )(((uint32_t )count_) - ((uint32_t )(((int32_t )(((int32_t )count_) % ((int32_t )16u)))))));
  if ((((int32_t )aligned_end_) > ((int32_t )0u))) {
    goto foreach_full_body_2e_lr_2e_ph_label;
  } else {
    counter_2e_1_2e_lcssa___PHI = 0u;   /* for PHI node */
    goto partial_inner_all_outer_label;
  }

foreach_full_body_2e_lr_2e_ph_label: {
  Sa_load_ptr2int_2void_ = ((uint8_t *)Sa_);
  Xa_load_ptr2int_2void_ = ((uint8_t *)Xa_);
  Ta_load_ptr2int_2void_ = ((uint8_t *)Ta_);
  ra_load_ptr2int_2void_ = ((uint8_t *)ra_);
  va_load_ptr2int_2void_ = ((uint8_t *)va_);
  tmp__10_ = ((uint8_t *)(&V_2e_i_));
  V_offset59_2e_i_ = (&V_2e_i_.array[((int64_t )0ull)]);
  result_load_ptr2int_2void_ = ((uint8_t *)result_);
  counter_2e_1324___PHI = 0u;   /* for PHI node */
  goto foreach_full_body_label;

}
  do {     /* Syntactic loop 'foreach_full_body' to make GCC happy */
foreach_full_body_label: {
  counter_2e_1324_ = counter_2e_1324___PHI;
  tmp__11_ = ((int64_t )(int32_t )(counter_2e_1324_ << 2u));
  ptr_masked_load256_ = __load<4>((((__vec16_f (*))((&Sa_load_ptr2int_2void_[((int64_t )tmp__11_)])))));
  ptr258_masked_load260_ = __load<4>((((__vec16_f (*))((&Xa_load_ptr2int_2void_[((int64_t )tmp__11_)])))));
  ptr263_masked_load265_ = __load<4>((((__vec16_f (*))((&Ta_load_ptr2int_2void_[((int64_t )tmp__11_)])))));
  ptr268_masked_load270_ = __load<4>((((__vec16_f (*))((&ra_load_ptr2int_2void_[((int64_t )tmp__11_)])))));
  ptr273_masked_load275_ = __load<4>((((__vec16_f (*))((&va_load_ptr2int_2void_[((int64_t )tmp__11_)])))));
  div_T_load__2e_i_ = __div(ptr263_masked_load265_, __smear_float<__vec16_f>(0x1p+6));
  calltmp_2e_i_2e_i_ = __sqrt_varying_float(div_T_load__2e_i_);
  calltmp_2e_i1_2e_i_ = __exp_varying_float((__mul(ptr273_masked_load275_, calltmp_2e_i_2e_i_)));
  div__u_load_2e_i_ = __div(__smear_float<__vec16_f>(0x1p+0), calltmp_2e_i1_2e_i_);
  calltmp_2e_i2_2e_i_ = __exp_varying_float((__mul(ptr268_masked_load270_, div_T_load__2e_i_)));
  sub_u_load15_d_load16_2e_i_ = __sub(calltmp_2e_i1_2e_i_, div__u_load_2e_i_);
  indvars_2e_iv333___PHI = 0ull;   /* for PHI node */
  goto for_loop_2e_i_label;

}
  do {     /* Syntactic loop 'for_loop.i' to make GCC happy */
for_loop_2e_i_label: {
  indvars_2e_iv333_ = indvars_2e_iv333___PHI;
  sub_mul__j_load21__to_float_2e_i_smear_ = __smear_float<__vec16_f>((((float )(int32_t )(((uint32_t )(((uint64_t )(((uint64_t )(indvars_2e_iv333_ << 1ull)) + ((uint64_t )4294967232ull)))))))));
  calltmp_2e_i3_2e_i_ = __pow_varying_float(calltmp_2e_i1_2e_i_, sub_mul__j_load21__to_float_2e_i_smear_);
  calltmp_2e_i4_2e_i_ = __max_varying_float(__setzero_float<__vec16_f>(), (__sub(ptr258_masked_load260_, (__mul(ptr_masked_load256_, calltmp_2e_i3_2e_i_)))));
  __store<64>(((&V_2e_i_.array[((int64_t )indvars_2e_iv333_)])), calltmp_2e_i4_2e_i_);
  indvars_2e_iv_2e_next334_ = ((uint64_t )(((uint64_t )indvars_2e_iv333_) + ((uint64_t )1ull)));
  if (((((uint32_t )indvars_2e_iv_2e_next334_)) == 64u)) {
    goto for_test30_2e_i_2e_loopexit_label;
  } else {
    indvars_2e_iv333___PHI = indvars_2e_iv_2e_next334_;   /* for PHI node */
    goto for_loop_2e_i_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop.i' */
for_test30_2e_i_2e_loopexit_label: {
  div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i_ = __div((__sub(calltmp_2e_i2_2e_i_, div__u_load_2e_i_)), sub_u_load15_d_load16_2e_i_);
  sub__Pu_load_2e_i_ = __sub(__smear_float<__vec16_f>(0x1p+0), div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i_);
  indvars_2e_iv341___PHI = 63u;   /* for PHI node */
  goto for_test39_2e_i_2e_preheader_label;

}
  do {     /* Syntactic loop 'for_test39.i.preheader' to make GCC happy */
for_test39_2e_i_2e_preheader_label: {
  indvars_2e_iv341_ = indvars_2e_iv341___PHI;
  if ((((int32_t )indvars_2e_iv341_) > ((int32_t )0u))) {
    indvars_2e_iv339___PHI = 0ull;   /* for PHI node */
    goto for_loop41_2e_i_label;
  } else {
    goto for_exit42_2e_i_label;
  }

}
  do {     /* Syntactic loop 'for_loop41.i' to make GCC happy */
for_loop41_2e_i_label: {
  indvars_2e_iv339_ = indvars_2e_iv339___PHI;
  V_offset48_2e_i_ = (&V_2e_i_.array[((int64_t )indvars_2e_iv339_)]);
  V_offset50_load_2e_i_ = __load<64>(V_offset48_2e_i_);
  indvars_2e_iv_2e_next340_ = ((uint64_t )(((uint64_t )indvars_2e_iv339_) + ((uint64_t )1ull)));
  V_offset54_load_2e_i_ = __load<64>(((&V_2e_i_.array[((int64_t )indvars_2e_iv_2e_next340_)])));
  __store<64>(V_offset48_2e_i_, (__div((__add((__mul(sub__Pu_load_2e_i_, V_offset50_load_2e_i_)), (__mul(div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i_, V_offset54_load_2e_i_)))), calltmp_2e_i2_2e_i_)));
  if (((((uint32_t )indvars_2e_iv_2e_next340_)) == indvars_2e_iv341_)) {
    goto for_exit42_2e_i_label;
  } else {
    indvars_2e_iv339___PHI = indvars_2e_iv_2e_next340_;   /* for PHI node */
    goto for_loop41_2e_i_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop41.i' */
for_exit42_2e_i_label: {
  indvars_2e_iv_2e_next342_ = ((uint32_t )(((uint32_t )indvars_2e_iv341_) + ((uint32_t )4294967295u)));
  if ((((int32_t )indvars_2e_iv_2e_next342_) > ((int32_t )4294967295u))) {
    indvars_2e_iv341___PHI = indvars_2e_iv_2e_next342_;   /* for PHI node */
    goto for_test39_2e_i_2e_preheader_label;
  } else {
    goto binomial_put___vyfvyfvyfvyfvyf_2e_exit_label;
  }

}
  } while (1); /* end of syntactic loop 'for_test39.i.preheader' */
binomial_put___vyfvyfvyfvyfvyf_2e_exit_label: {
  V_offset59_load_2e_i_ = __load<64>(V_offset59_2e_i_);
  __store<4>((((__vec16_f (*))((&result_load_ptr2int_2void_[((int64_t )tmp__11_)])))), V_offset59_load_2e_i_);
  new_counter_ = ((uint32_t )(((uint32_t )counter_2e_1324_) + ((uint32_t )16u)));
  if ((((int32_t )new_counter_) < ((int32_t )aligned_end_))) {
    counter_2e_1324___PHI = new_counter_;   /* for PHI node */
    goto foreach_full_body_label;
  } else {
    counter_2e_1_2e_lcssa___PHI = new_counter_;   /* for PHI node */
    goto partial_inner_all_outer_label;
  }

}
  } while (1); /* end of syntactic loop 'foreach_full_body' */
for_test30_2e_i230_2e_preheader_label: {
  div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i211_ = __div((__sub(calltmp_2e_i2_2e_i208_, div__u_load_2e_i206_)), sub_u_load15_d_load16_2e_i210_);
  sub__Pu_load_2e_i239_ = __sub(__smear_float<__vec16_f>(0x1p+0), div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i211_);
  indvars_2e_iv325___PHI = 63u;   /* for PHI node */
  goto for_test39_2e_i236_2e_preheader_label;

}
  do {     /* Syntactic loop 'for_loop.i227' to make GCC happy */
for_loop_2e_i227_label: {
  indvars_2e_iv327_ = indvars_2e_iv327___PHI;
  sub_mul__j_load21__to_float_2e_i217_smear_ = __smear_float<__vec16_f>((((float )(int32_t )(((uint32_t )(((uint64_t )(((uint64_t )(indvars_2e_iv327_ << 1ull)) + ((uint64_t )4294967232ull)))))))));
  calltmp_2e_i3_2e_i220_ = __pow_varying_float(calltmp_2e_i1_2e_i205_, sub_mul__j_load21__to_float_2e_i217_smear_);
  calltmp_2e_i4_2e_i225_ = __max_varying_float(__setzero_float<__vec16_f>(), (__sub(ptr288_masked_load_, (__mul(ptr282_masked_load_, calltmp_2e_i3_2e_i220_)))));
  __store<64>(((&V_2e_i_.array[((int64_t )indvars_2e_iv327_)])), calltmp_2e_i4_2e_i225_);
  indvars_2e_iv_2e_next328_ = ((uint64_t )(((uint64_t )indvars_2e_iv327_) + ((uint64_t )1ull)));
  if (((((uint32_t )indvars_2e_iv_2e_next328_)) == 64u)) {
    goto for_test30_2e_i230_2e_preheader_label;
  } else {
    indvars_2e_iv327___PHI = indvars_2e_iv_2e_next328_;   /* for PHI node */
    goto for_loop_2e_i227_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop.i227' */
  do {     /* Syntactic loop 'for_test39.i236.preheader' to make GCC happy */
for_test39_2e_i236_2e_preheader_label: {
  indvars_2e_iv325_ = indvars_2e_iv325___PHI;
  if ((((int32_t )indvars_2e_iv325_) > ((int32_t )0u))) {
    indvars_2e_iv___PHI = 0ull;   /* for PHI node */
    goto for_loop41_2e_i252_label;
  } else {
    goto for_exit42_2e_i254_label;
  }

}
  do {     /* Syntactic loop 'for_loop41.i252' to make GCC happy */
for_loop41_2e_i252_label: {
  indvars_2e_iv_ = indvars_2e_iv___PHI;
  V_offset48_2e_i238_ = (&V_2e_i_.array[((int64_t )indvars_2e_iv_)]);
  V_offset50_load_2e_i242_ = __load<64>(V_offset48_2e_i238_);
  indvars_2e_iv_2e_next_ = ((uint64_t )(((uint64_t )indvars_2e_iv_) + ((uint64_t )1ull)));
  V_offset54_load_2e_i247_ = __load<64>(((&V_2e_i_.array[((int64_t )indvars_2e_iv_2e_next_)])));
  __store<64>(V_offset48_2e_i238_, (__div((__add((__mul(sub__Pu_load_2e_i239_, V_offset50_load_2e_i242_)), (__mul(div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i211_, V_offset54_load_2e_i247_)))), calltmp_2e_i2_2e_i208_)));
  if (((((uint32_t )indvars_2e_iv_2e_next_)) == indvars_2e_iv325_)) {
    goto for_exit42_2e_i254_label;
  } else {
    indvars_2e_iv___PHI = indvars_2e_iv_2e_next_;   /* for PHI node */
    goto for_loop41_2e_i252_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop41.i252' */
for_exit42_2e_i254_label: {
  indvars_2e_iv_2e_next326_ = ((uint32_t )(((uint32_t )indvars_2e_iv325_) + ((uint32_t )4294967295u)));
  if ((((int32_t )indvars_2e_iv_2e_next326_) > ((int32_t )4294967295u))) {
    indvars_2e_iv325___PHI = indvars_2e_iv_2e_next326_;   /* for PHI node */
    goto for_test39_2e_i236_2e_preheader_label;
  } else {
    goto binomial_put___vyfvyfvyfvyfvyf_2e_exit255_label;
  }

}
  } while (1); /* end of syntactic loop 'for_test39.i236.preheader' */
binomial_put___vyfvyfvyfvyfvyf_2e_exit255_label: {
  V_offset59_load_2e_i232_ = __load<64>(((&V_2e_i_.array[((int64_t )0ull)])));
  __masked_store_float((((__vec16_f (*))((&(((uint8_t *)result_))[((int64_t )tmp__12_)])))), V_offset59_load_2e_i232_, cmp70_);
  goto foreach_reset_label;

}
foreach_reset_label: {
  return;
}
partial_inner_all_outer_label: {
  counter_2e_1_2e_lcssa_ = counter_2e_1_2e_lcssa___PHI;
  if ((((int32_t )counter_2e_1_2e_lcssa_) < ((int32_t )count_))) {
    goto partial_inner_only_label;
  } else {
    goto foreach_reset_label;
  }

}
partial_inner_only_label: {
  counter_2e_1_2e_lcssa_smear_ = __smear_i32<__vec16_i32>(counter_2e_1_2e_lcssa_);
  count_smear_ = __smear_i32<__vec16_i32>(count_);
  cmp70_ = __signed_less_than_i32((__add(counter_2e_1_2e_lcssa_smear_, __load<64>((const __vec16_i32  *)(VectorConstant2)))), count_smear_);
  tmp__12_ = ((int64_t )(int32_t )(counter_2e_1_2e_lcssa_ << 2u));
  ptr282_masked_load_ = __masked_load_float(((&(((uint8_t *)Sa_))[((int64_t )tmp__12_)])), cmp70_);
  ptr288_masked_load_ = __masked_load_float(((&(((uint8_t *)Xa_))[((int64_t )tmp__12_)])), cmp70_);
  ptr294_masked_load_ = __masked_load_float(((&(((uint8_t *)Ta_))[((int64_t )tmp__12_)])), cmp70_);
  ptr300_masked_load_ = __masked_load_float(((&(((uint8_t *)ra_))[((int64_t )tmp__12_)])), cmp70_);
  ptr306_masked_load_ = __masked_load_float(((&(((uint8_t *)va_))[((int64_t )tmp__12_)])), cmp70_);
  tmp__13_ = ((uint8_t *)(&V_2e_i_));
  div_T_load__2e_i202_ = __div(ptr294_masked_load_, __smear_float<__vec16_f>(0x1p+6));
  calltmp_2e_i_2e_i203_ = __sqrt_varying_float(div_T_load__2e_i202_);
  calltmp_2e_i1_2e_i205_ = __exp_varying_float((__mul(ptr306_masked_load_, calltmp_2e_i_2e_i203_)));
  div__u_load_2e_i206_ = __div(__smear_float<__vec16_f>(0x1p+0), calltmp_2e_i1_2e_i205_);
  calltmp_2e_i2_2e_i208_ = __exp_varying_float((__mul(ptr300_masked_load_, div_T_load__2e_i202_)));
  sub_u_load15_d_load16_2e_i210_ = __sub(calltmp_2e_i1_2e_i205_, div__u_load_2e_i206_);
  indvars_2e_iv327___PHI = 0ull;   /* for PHI node */
  goto for_loop_2e_i227_label;

}
}


static const int32_t __attribute__ ((aligned(64))) VectorConstant3[] = { 0u, 1u, 2u, 3u, 4u, 5u, 6u, 7u, 8u, 9u, 10u, 11u, 12u, 13u, 14u, 15u,  };

void binomial_task___un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_uni(l_unnamed_0 *tmp__14_, uint32_t tmp__15_, uint32_t tmp__16_, uint32_t tmp__17_, uint32_t tmp__18_) {
  l_array_1 V_2e_i_;    /* Address-exposed local */
  float *Sa2_;
  float *Xa4_;
  float *Ta6_;
  float *ra8_;
  float *va10_;
  float *result12_;
  uint32_t count14_;
  uint32_t div_count_load_taskCount_load_;
  uint32_t mul_taskIndex_load_div_count_load_taskCount_load_;
  uint32_t calltmp_2e_i_;
  uint32_t aligned_end_;
  uint8_t *Sa_load_ptr2int_2void_;
  uint8_t *Xa_load_ptr2int_2void_;
  uint8_t *Ta_load_ptr2int_2void_;
  uint8_t *ra_load_ptr2int_2void_;
  uint8_t *va_load_ptr2int_2void_;
  uint8_t *tmp__19_;
  __vec16_f (*V_offset59_2e_i_);
  uint8_t *result_load_ptr2int_2void_;
  uint32_t counter_2e_1338_;
  uint32_t counter_2e_1338___PHI;
  uint64_t tmp__20_;
  __vec16_f ptr_masked_load270_;
  __vec16_f ptr272_masked_load274_;
  __vec16_f ptr277_masked_load279_;
  __vec16_f ptr282_masked_load284_;
  __vec16_f ptr287_masked_load289_;
  __vec16_f div_T_load__2e_i_;
  __vec16_f calltmp_2e_i_2e_i_;
  __vec16_f calltmp_2e_i1_2e_i_;
  __vec16_f div__u_load_2e_i_;
  __vec16_f calltmp_2e_i2_2e_i_;
  __vec16_f sub_u_load15_d_load16_2e_i_;
  uint64_t indvars_2e_iv347_;
  uint64_t indvars_2e_iv347___PHI;
  __vec16_f sub_mul__j_load21__to_float_2e_i_smear_;
  __vec16_f calltmp_2e_i3_2e_i_;
  __vec16_f calltmp_2e_i4_2e_i_;
  uint64_t indvars_2e_iv_2e_next348_;
  __vec16_f div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i_;
  __vec16_f sub__Pu_load_2e_i_;
  uint32_t indvars_2e_iv355_;
  uint32_t indvars_2e_iv355___PHI;
  uint64_t indvars_2e_iv353_;
  uint64_t indvars_2e_iv353___PHI;
  __vec16_f (*V_offset48_2e_i_);
  __vec16_f V_offset50_load_2e_i_;
  uint64_t indvars_2e_iv_2e_next354_;
  __vec16_f V_offset54_load_2e_i_;
  uint32_t indvars_2e_iv_2e_next356_;
  __vec16_f V_offset59_load_2e_i_;
  uint32_t new_counter_;
  __vec16_f div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i225_;
  __vec16_f sub__Pu_load_2e_i253_;
  uint64_t indvars_2e_iv341_;
  uint64_t indvars_2e_iv341___PHI;
  __vec16_f sub_mul__j_load21__to_float_2e_i231_smear_;
  __vec16_f calltmp_2e_i3_2e_i234_;
  __vec16_f calltmp_2e_i4_2e_i239_;
  uint64_t indvars_2e_iv_2e_next342_;
  uint32_t indvars_2e_iv339_;
  uint32_t indvars_2e_iv339___PHI;
  uint64_t indvars_2e_iv_;
  uint64_t indvars_2e_iv___PHI;
  __vec16_f (*V_offset48_2e_i252_);
  __vec16_f V_offset50_load_2e_i256_;
  uint64_t indvars_2e_iv_2e_next_;
  __vec16_f V_offset54_load_2e_i261_;
  uint32_t indvars_2e_iv_2e_next340_;
  __vec16_f V_offset59_load_2e_i246_;
  uint32_t counter_2e_1_2e_lcssa_;
  uint32_t counter_2e_1_2e_lcssa___PHI;
  __vec16_i32 counter_2e_1_2e_lcssa_smear_;
  __vec16_i32 calltmp_2e_i_smear_;
  __vec16_i1 cmp84_;
  uint64_t tmp__21_;
  __vec16_f ptr296_masked_load_;
  __vec16_f ptr302_masked_load_;
  __vec16_f ptr308_masked_load_;
  __vec16_f ptr314_masked_load_;
  __vec16_f ptr320_masked_load_;
  uint8_t *tmp__22_;
  __vec16_f div_T_load__2e_i216_;
  __vec16_f calltmp_2e_i_2e_i217_;
  __vec16_f calltmp_2e_i1_2e_i219_;
  __vec16_f div__u_load_2e_i220_;
  __vec16_f calltmp_2e_i2_2e_i222_;
  __vec16_f sub_u_load15_d_load16_2e_i224_;

  Sa2_ = *((&tmp__14_->field0));
  Xa4_ = *((&tmp__14_->field1));
  Ta6_ = *((&tmp__14_->field2));
  ra8_ = *((&tmp__14_->field3));
  va10_ = *((&tmp__14_->field4));
  result12_ = *((&tmp__14_->field5));
  count14_ = *((&tmp__14_->field6));
  div_count_load_taskCount_load_ = ((uint32_t )(((uint32_t )count14_) / ((uint32_t )tmp__18_)));
  mul_taskIndex_load_div_count_load_taskCount_load_ = ((uint32_t )(((uint32_t )div_count_load_taskCount_load_) * ((uint32_t )tmp__17_)));
  calltmp_2e_i_ = __min_uniform_int32(count14_, (((uint32_t )(((uint32_t )div_count_load_taskCount_load_) * ((uint32_t )(((uint32_t )(((uint32_t )tmp__17_) + ((uint32_t )1u)))))))));
  aligned_end_ = ((uint32_t )(((uint32_t )calltmp_2e_i_) - ((uint32_t )(((int32_t )(((int32_t )(((uint32_t )(((uint32_t )calltmp_2e_i_) - ((uint32_t )mul_taskIndex_load_div_count_load_taskCount_load_))))) % ((int32_t )16u)))))));
  if ((((int32_t )mul_taskIndex_load_div_count_load_taskCount_load_) < ((int32_t )aligned_end_))) {
    goto foreach_full_body_2e_lr_2e_ph_label;
  } else {
    counter_2e_1_2e_lcssa___PHI = mul_taskIndex_load_div_count_load_taskCount_load_;   /* for PHI node */
    goto partial_inner_all_outer_label;
  }

foreach_full_body_2e_lr_2e_ph_label: {
  Sa_load_ptr2int_2void_ = ((uint8_t *)Sa2_);
  Xa_load_ptr2int_2void_ = ((uint8_t *)Xa4_);
  Ta_load_ptr2int_2void_ = ((uint8_t *)Ta6_);
  ra_load_ptr2int_2void_ = ((uint8_t *)ra8_);
  va_load_ptr2int_2void_ = ((uint8_t *)va10_);
  tmp__19_ = ((uint8_t *)(&V_2e_i_));
  V_offset59_2e_i_ = (&V_2e_i_.array[((int64_t )0ull)]);
  result_load_ptr2int_2void_ = ((uint8_t *)result12_);
  counter_2e_1338___PHI = mul_taskIndex_load_div_count_load_taskCount_load_;   /* for PHI node */
  goto foreach_full_body_label;

}
  do {     /* Syntactic loop 'foreach_full_body' to make GCC happy */
foreach_full_body_label: {
  counter_2e_1338_ = counter_2e_1338___PHI;
  tmp__20_ = ((int64_t )(int32_t )(counter_2e_1338_ << 2u));
  ptr_masked_load270_ = __load<4>((((__vec16_f (*))((&Sa_load_ptr2int_2void_[((int64_t )tmp__20_)])))));
  ptr272_masked_load274_ = __load<4>((((__vec16_f (*))((&Xa_load_ptr2int_2void_[((int64_t )tmp__20_)])))));
  ptr277_masked_load279_ = __load<4>((((__vec16_f (*))((&Ta_load_ptr2int_2void_[((int64_t )tmp__20_)])))));
  ptr282_masked_load284_ = __load<4>((((__vec16_f (*))((&ra_load_ptr2int_2void_[((int64_t )tmp__20_)])))));
  ptr287_masked_load289_ = __load<4>((((__vec16_f (*))((&va_load_ptr2int_2void_[((int64_t )tmp__20_)])))));
  div_T_load__2e_i_ = __div(ptr277_masked_load279_, __smear_float<__vec16_f>(0x1p+6));
  calltmp_2e_i_2e_i_ = __sqrt_varying_float(div_T_load__2e_i_);
  calltmp_2e_i1_2e_i_ = __exp_varying_float((__mul(ptr287_masked_load289_, calltmp_2e_i_2e_i_)));
  div__u_load_2e_i_ = __div(__smear_float<__vec16_f>(0x1p+0), calltmp_2e_i1_2e_i_);
  calltmp_2e_i2_2e_i_ = __exp_varying_float((__mul(ptr282_masked_load284_, div_T_load__2e_i_)));
  sub_u_load15_d_load16_2e_i_ = __sub(calltmp_2e_i1_2e_i_, div__u_load_2e_i_);
  indvars_2e_iv347___PHI = 0ull;   /* for PHI node */
  goto for_loop_2e_i_label;

}
  do {     /* Syntactic loop 'for_loop.i' to make GCC happy */
for_loop_2e_i_label: {
  indvars_2e_iv347_ = indvars_2e_iv347___PHI;
  sub_mul__j_load21__to_float_2e_i_smear_ = __smear_float<__vec16_f>((((float )(int32_t )(((uint32_t )(((uint64_t )(((uint64_t )(indvars_2e_iv347_ << 1ull)) + ((uint64_t )4294967232ull)))))))));
  calltmp_2e_i3_2e_i_ = __pow_varying_float(calltmp_2e_i1_2e_i_, sub_mul__j_load21__to_float_2e_i_smear_);
  calltmp_2e_i4_2e_i_ = __max_varying_float(__setzero_float<__vec16_f>(), (__sub(ptr272_masked_load274_, (__mul(ptr_masked_load270_, calltmp_2e_i3_2e_i_)))));
  __store<64>(((&V_2e_i_.array[((int64_t )indvars_2e_iv347_)])), calltmp_2e_i4_2e_i_);
  indvars_2e_iv_2e_next348_ = ((uint64_t )(((uint64_t )indvars_2e_iv347_) + ((uint64_t )1ull)));
  if (((((uint32_t )indvars_2e_iv_2e_next348_)) == 64u)) {
    goto for_test30_2e_i_2e_loopexit_label;
  } else {
    indvars_2e_iv347___PHI = indvars_2e_iv_2e_next348_;   /* for PHI node */
    goto for_loop_2e_i_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop.i' */
for_test30_2e_i_2e_loopexit_label: {
  div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i_ = __div((__sub(calltmp_2e_i2_2e_i_, div__u_load_2e_i_)), sub_u_load15_d_load16_2e_i_);
  sub__Pu_load_2e_i_ = __sub(__smear_float<__vec16_f>(0x1p+0), div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i_);
  indvars_2e_iv355___PHI = 63u;   /* for PHI node */
  goto for_test39_2e_i_2e_preheader_label;

}
  do {     /* Syntactic loop 'for_test39.i.preheader' to make GCC happy */
for_test39_2e_i_2e_preheader_label: {
  indvars_2e_iv355_ = indvars_2e_iv355___PHI;
  if ((((int32_t )indvars_2e_iv355_) > ((int32_t )0u))) {
    indvars_2e_iv353___PHI = 0ull;   /* for PHI node */
    goto for_loop41_2e_i_label;
  } else {
    goto for_exit42_2e_i_label;
  }

}
  do {     /* Syntactic loop 'for_loop41.i' to make GCC happy */
for_loop41_2e_i_label: {
  indvars_2e_iv353_ = indvars_2e_iv353___PHI;
  V_offset48_2e_i_ = (&V_2e_i_.array[((int64_t )indvars_2e_iv353_)]);
  V_offset50_load_2e_i_ = __load<64>(V_offset48_2e_i_);
  indvars_2e_iv_2e_next354_ = ((uint64_t )(((uint64_t )indvars_2e_iv353_) + ((uint64_t )1ull)));
  V_offset54_load_2e_i_ = __load<64>(((&V_2e_i_.array[((int64_t )indvars_2e_iv_2e_next354_)])));
  __store<64>(V_offset48_2e_i_, (__div((__add((__mul(sub__Pu_load_2e_i_, V_offset50_load_2e_i_)), (__mul(div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i_, V_offset54_load_2e_i_)))), calltmp_2e_i2_2e_i_)));
  if (((((uint32_t )indvars_2e_iv_2e_next354_)) == indvars_2e_iv355_)) {
    goto for_exit42_2e_i_label;
  } else {
    indvars_2e_iv353___PHI = indvars_2e_iv_2e_next354_;   /* for PHI node */
    goto for_loop41_2e_i_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop41.i' */
for_exit42_2e_i_label: {
  indvars_2e_iv_2e_next356_ = ((uint32_t )(((uint32_t )indvars_2e_iv355_) + ((uint32_t )4294967295u)));
  if ((((int32_t )indvars_2e_iv_2e_next356_) > ((int32_t )4294967295u))) {
    indvars_2e_iv355___PHI = indvars_2e_iv_2e_next356_;   /* for PHI node */
    goto for_test39_2e_i_2e_preheader_label;
  } else {
    goto binomial_put___vyfvyfvyfvyfvyf_2e_exit_label;
  }

}
  } while (1); /* end of syntactic loop 'for_test39.i.preheader' */
binomial_put___vyfvyfvyfvyfvyf_2e_exit_label: {
  V_offset59_load_2e_i_ = __load<64>(V_offset59_2e_i_);
  __store<4>((((__vec16_f (*))((&result_load_ptr2int_2void_[((int64_t )tmp__20_)])))), V_offset59_load_2e_i_);
  new_counter_ = ((uint32_t )(((uint32_t )counter_2e_1338_) + ((uint32_t )16u)));
  if ((((int32_t )new_counter_) < ((int32_t )aligned_end_))) {
    counter_2e_1338___PHI = new_counter_;   /* for PHI node */
    goto foreach_full_body_label;
  } else {
    counter_2e_1_2e_lcssa___PHI = new_counter_;   /* for PHI node */
    goto partial_inner_all_outer_label;
  }

}
  } while (1); /* end of syntactic loop 'foreach_full_body' */
for_test30_2e_i244_2e_preheader_label: {
  div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i225_ = __div((__sub(calltmp_2e_i2_2e_i222_, div__u_load_2e_i220_)), sub_u_load15_d_load16_2e_i224_);
  sub__Pu_load_2e_i253_ = __sub(__smear_float<__vec16_f>(0x1p+0), div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i225_);
  indvars_2e_iv339___PHI = 63u;   /* for PHI node */
  goto for_test39_2e_i250_2e_preheader_label;

}
  do {     /* Syntactic loop 'for_loop.i241' to make GCC happy */
for_loop_2e_i241_label: {
  indvars_2e_iv341_ = indvars_2e_iv341___PHI;
  sub_mul__j_load21__to_float_2e_i231_smear_ = __smear_float<__vec16_f>((((float )(int32_t )(((uint32_t )(((uint64_t )(((uint64_t )(indvars_2e_iv341_ << 1ull)) + ((uint64_t )4294967232ull)))))))));
  calltmp_2e_i3_2e_i234_ = __pow_varying_float(calltmp_2e_i1_2e_i219_, sub_mul__j_load21__to_float_2e_i231_smear_);
  calltmp_2e_i4_2e_i239_ = __max_varying_float(__setzero_float<__vec16_f>(), (__sub(ptr302_masked_load_, (__mul(ptr296_masked_load_, calltmp_2e_i3_2e_i234_)))));
  __store<64>(((&V_2e_i_.array[((int64_t )indvars_2e_iv341_)])), calltmp_2e_i4_2e_i239_);
  indvars_2e_iv_2e_next342_ = ((uint64_t )(((uint64_t )indvars_2e_iv341_) + ((uint64_t )1ull)));
  if (((((uint32_t )indvars_2e_iv_2e_next342_)) == 64u)) {
    goto for_test30_2e_i244_2e_preheader_label;
  } else {
    indvars_2e_iv341___PHI = indvars_2e_iv_2e_next342_;   /* for PHI node */
    goto for_loop_2e_i241_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop.i241' */
  do {     /* Syntactic loop 'for_test39.i250.preheader' to make GCC happy */
for_test39_2e_i250_2e_preheader_label: {
  indvars_2e_iv339_ = indvars_2e_iv339___PHI;
  if ((((int32_t )indvars_2e_iv339_) > ((int32_t )0u))) {
    indvars_2e_iv___PHI = 0ull;   /* for PHI node */
    goto for_loop41_2e_i266_label;
  } else {
    goto for_exit42_2e_i268_label;
  }

}
  do {     /* Syntactic loop 'for_loop41.i266' to make GCC happy */
for_loop41_2e_i266_label: {
  indvars_2e_iv_ = indvars_2e_iv___PHI;
  V_offset48_2e_i252_ = (&V_2e_i_.array[((int64_t )indvars_2e_iv_)]);
  V_offset50_load_2e_i256_ = __load<64>(V_offset48_2e_i252_);
  indvars_2e_iv_2e_next_ = ((uint64_t )(((uint64_t )indvars_2e_iv_) + ((uint64_t )1ull)));
  V_offset54_load_2e_i261_ = __load<64>(((&V_2e_i_.array[((int64_t )indvars_2e_iv_2e_next_)])));
  __store<64>(V_offset48_2e_i252_, (__div((__add((__mul(sub__Pu_load_2e_i253_, V_offset50_load_2e_i256_)), (__mul(div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i225_, V_offset54_load_2e_i261_)))), calltmp_2e_i2_2e_i222_)));
  if (((((uint32_t )indvars_2e_iv_2e_next_)) == indvars_2e_iv339_)) {
    goto for_exit42_2e_i268_label;
  } else {
    indvars_2e_iv___PHI = indvars_2e_iv_2e_next_;   /* for PHI node */
    goto for_loop41_2e_i266_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop41.i266' */
for_exit42_2e_i268_label: {
  indvars_2e_iv_2e_next340_ = ((uint32_t )(((uint32_t )indvars_2e_iv339_) + ((uint32_t )4294967295u)));
  if ((((int32_t )indvars_2e_iv_2e_next340_) > ((int32_t )4294967295u))) {
    indvars_2e_iv339___PHI = indvars_2e_iv_2e_next340_;   /* for PHI node */
    goto for_test39_2e_i250_2e_preheader_label;
  } else {
    goto binomial_put___vyfvyfvyfvyfvyf_2e_exit269_label;
  }

}
  } while (1); /* end of syntactic loop 'for_test39.i250.preheader' */
binomial_put___vyfvyfvyfvyfvyf_2e_exit269_label: {
  V_offset59_load_2e_i246_ = __load<64>(((&V_2e_i_.array[((int64_t )0ull)])));
  __masked_store_float((((__vec16_f (*))((&(((uint8_t *)result12_))[((int64_t )tmp__21_)])))), V_offset59_load_2e_i246_, cmp84_);
  goto foreach_reset_label;

}
foreach_reset_label: {
  return;
}
partial_inner_all_outer_label: {
  counter_2e_1_2e_lcssa_ = counter_2e_1_2e_lcssa___PHI;
  if ((((int32_t )counter_2e_1_2e_lcssa_) < ((int32_t )calltmp_2e_i_))) {
    goto partial_inner_only_label;
  } else {
    goto foreach_reset_label;
  }

}
partial_inner_only_label: {
  counter_2e_1_2e_lcssa_smear_ = __smear_i32<__vec16_i32>(counter_2e_1_2e_lcssa_);
  calltmp_2e_i_smear_ = __smear_i32<__vec16_i32>(calltmp_2e_i_);
  cmp84_ = __signed_less_than_i32((__add(counter_2e_1_2e_lcssa_smear_, __load<64>((const __vec16_i32  *)(VectorConstant3)))), calltmp_2e_i_smear_);
  tmp__21_ = ((int64_t )(int32_t )(counter_2e_1_2e_lcssa_ << 2u));
  ptr296_masked_load_ = __masked_load_float(((&(((uint8_t *)Sa2_))[((int64_t )tmp__21_)])), cmp84_);
  ptr302_masked_load_ = __masked_load_float(((&(((uint8_t *)Xa4_))[((int64_t )tmp__21_)])), cmp84_);
  ptr308_masked_load_ = __masked_load_float(((&(((uint8_t *)Ta6_))[((int64_t )tmp__21_)])), cmp84_);
  ptr314_masked_load_ = __masked_load_float(((&(((uint8_t *)ra8_))[((int64_t )tmp__21_)])), cmp84_);
  ptr320_masked_load_ = __masked_load_float(((&(((uint8_t *)va10_))[((int64_t )tmp__21_)])), cmp84_);
  tmp__22_ = ((uint8_t *)(&V_2e_i_));
  div_T_load__2e_i216_ = __div(ptr308_masked_load_, __smear_float<__vec16_f>(0x1p+6));
  calltmp_2e_i_2e_i217_ = __sqrt_varying_float(div_T_load__2e_i216_);
  calltmp_2e_i1_2e_i219_ = __exp_varying_float((__mul(ptr320_masked_load_, calltmp_2e_i_2e_i217_)));
  div__u_load_2e_i220_ = __div(__smear_float<__vec16_f>(0x1p+0), calltmp_2e_i1_2e_i219_);
  calltmp_2e_i2_2e_i222_ = __exp_varying_float((__mul(ptr314_masked_load_, div_T_load__2e_i216_)));
  sub_u_load15_d_load16_2e_i224_ = __sub(calltmp_2e_i1_2e_i219_, div__u_load_2e_i220_);
  indvars_2e_iv341___PHI = 0ull;   /* for PHI node */
  goto for_loop_2e_i241_label;

}
}



void binomial_put_ispc_tasks___un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_uni(float *Sa_, float *Xa_, float *Ta_, float *ra_, float *va_, float *result_, uint32_t count_, __vec16_i1 __mask_) {
  uint8_t *launch_group_handle_;    /* Address-exposed local */
  uint32_t calltmp_2e_i_;
  uint8_t *args_ptr_;
  uint8_t *launch_group_handle_load_;

  *(&launch_group_handle_) = ((uint8_t *)/*NULL*/0);
  calltmp_2e_i_ = __max_uniform_int32(64u, (((int32_t )(((int32_t )count_) / ((int32_t )16384u)))));
  args_ptr_ = ISPCAlloc((&launch_group_handle_), 56ull, 64u);
  *(((float **)args_ptr_)) = Sa_;
  *(((float **)((&args_ptr_[((int64_t )8ull)])))) = Xa_;
  *(((float **)((&args_ptr_[((int64_t )16ull)])))) = Ta_;
  *(((float **)((&args_ptr_[((int64_t )24ull)])))) = ra_;
  *(((float **)((&args_ptr_[((int64_t )32ull)])))) = va_;
  *(((float **)((&args_ptr_[((int64_t )40ull)])))) = result_;
  *(((uint32_t *)((&args_ptr_[((int64_t )48ull)])))) = count_;
  __store<2>((((__vec16_i1 (*))((&args_ptr_[((int64_t )52ull)])))), __mask_);
  ISPCLaunch((&launch_group_handle_), ((uint8_t *)binomial_task___un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_uni), args_ptr_, calltmp_2e_i_);
  launch_group_handle_load_ = *(&launch_group_handle_);
  if ((launch_group_handle_load_ == ((uint8_t *)/*NULL*/0))) {
    goto post_sync_label;
  } else {
    goto call_sync_label;
  }

call_sync_label: {
  ISPCSync(launch_group_handle_load_);
  *(&launch_group_handle_) = ((uint8_t *)/*NULL*/0);
  goto post_sync_label;

}
post_sync_label: {
  return;
}
}



void black_scholes_ispc_tasks(float *Sa_, float *Xa_, float *Ta_, float *ra_, float *va_, float *result_, uint32_t count_) {
  uint8_t *launch_group_handle_;    /* Address-exposed local */
  uint32_t calltmp_2e_i_;
  uint8_t *args_ptr_;
  uint8_t *launch_group_handle_load_;

  *(&launch_group_handle_) = ((uint8_t *)/*NULL*/0);
  calltmp_2e_i_ = __max_uniform_int32(64u, (((int32_t )(((int32_t )count_) / ((int32_t )16384u)))));
  args_ptr_ = ISPCAlloc((&launch_group_handle_), 56ull, 64u);
  *(((float **)args_ptr_)) = Sa_;
  *(((float **)((&args_ptr_[((int64_t )8ull)])))) = Xa_;
  *(((float **)((&args_ptr_[((int64_t )16ull)])))) = Ta_;
  *(((float **)((&args_ptr_[((int64_t )24ull)])))) = ra_;
  *(((float **)((&args_ptr_[((int64_t )32ull)])))) = va_;
  *(((float **)((&args_ptr_[((int64_t )40ull)])))) = result_;
  *(((uint32_t *)((&args_ptr_[((int64_t )48ull)])))) = count_;
  __store<2>((((__vec16_i1 (*))((&args_ptr_[((int64_t )52ull)])))), __smear_i1<__vec16_i1>(1));
  ISPCLaunch((&launch_group_handle_), ((uint8_t *)bs_task___un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_uni), args_ptr_, calltmp_2e_i_);
  launch_group_handle_load_ = *(&launch_group_handle_);
  if ((launch_group_handle_load_ == ((uint8_t *)/*NULL*/0))) {
    goto post_sync_label;
  } else {
    goto call_sync_label;
  }

call_sync_label: {
  ISPCSync(launch_group_handle_load_);
  *(&launch_group_handle_) = ((uint8_t *)/*NULL*/0);
  goto post_sync_label;

}
post_sync_label: {
  return;
}
}


static const int32_t __attribute__ ((aligned(64))) VectorConstant4[] = { 0u, 1u, 2u, 3u, 4u, 5u, 6u, 7u, 8u, 9u, 10u, 11u, 12u, 13u, 14u, 15u,  };

void black_scholes_ispc(float *Sa_, float *Xa_, float *Ta_, float *ra_, float *va_, float *result_, uint32_t count_) {
  uint32_t aligned_end_;
  uint8_t *Sa_load_ptr2int_2void_;
  uint8_t *Xa_load_ptr2int_2void_;
  uint8_t *Ta_load_ptr2int_2void_;
  uint8_t *ra_load_ptr2int_2void_;
  uint8_t *va_load_ptr2int_2void_;
  uint8_t *result_load_ptr2int_2void_;
  uint32_t counter_2e_1435_;
  uint32_t counter_2e_1435___PHI;
  uint64_t tmp__23_;
  __vec16_f ptr_masked_load363_;
  __vec16_f ptr365_masked_load367_;
  __vec16_f ptr370_masked_load372_;
  __vec16_f ptr375_masked_load377_;
  __vec16_f ptr380_masked_load382_;
  __vec16_f calltmp_2e_i_;
  __vec16_f calltmp_2e_i254_;
  __vec16_f div_add_calltmp_mul_add_r_load_mul_mul_v_load_v_load54__T_load_mul_v_load55_calltmp59_;
  __vec16_f calltmp_2e_i255_;
  __vec16_f sub_d1_load_mul_v_load60_calltmp64_;
  __vec16_f int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i_;
  __vec16_f div__add__mul__L_load_2e_i_;
  __vec16_f mul_k_load_k_load4_2e_i_;
  __vec16_f mul_k2_load_k_load5_2e_i_;
  __vec16_f calltmp_2e_i_2e_i_;
  __vec16_f mul_w_load_mul__calltmp16_2e_i_;
  __vec16_f v1_2e_i_;
  __vec16_f calltmp_2e_i256_;
  __vec16_f int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i262_;
  __vec16_f div__add__mul__L_load_2e_i266_;
  __vec16_f mul_k_load_k_load4_2e_i267_;
  __vec16_f mul_k2_load_k_load5_2e_i268_;
  __vec16_f calltmp_2e_i_2e_i283_;
  __vec16_f mul_w_load_mul__calltmp16_2e_i286_;
  __vec16_f v1_2e_i433_;
  uint32_t new_counter_;
  uint32_t counter_2e_1_2e_lcssa_;
  uint32_t counter_2e_1_2e_lcssa___PHI;
  __vec16_i32 counter_2e_1_2e_lcssa_smear_;
  __vec16_i32 count_smear_;
  __vec16_i1 cmp95_;
  uint64_t tmp__24_;
  __vec16_f ptr392_masked_load_;
  __vec16_f ptr398_masked_load_;
  __vec16_f ptr404_masked_load_;
  __vec16_f ptr410_masked_load_;
  __vec16_f ptr416_masked_load_;
  __vec16_f calltmp_2e_i291_;
  __vec16_f calltmp_2e_i292_;
  __vec16_f div_add_calltmp140_mul_add_r_load141_mul_mul_v_load142_v_load143__T_load144_mul_v_load145_calltmp149_;
  __vec16_f calltmp_2e_i293_;
  __vec16_f sub_d1_load151_mul_v_load152_calltmp156_;
  __vec16_f int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i299_;
  __vec16_f div__add__mul__L_load_2e_i303_;
  __vec16_f mul_k_load_k_load4_2e_i304_;
  __vec16_f mul_k2_load_k_load5_2e_i305_;
  __vec16_f calltmp_2e_i_2e_i320_;
  __vec16_f mul_w_load_mul__calltmp16_2e_i323_;
  __vec16_f v1_2e_i431_;
  __vec16_f calltmp_2e_i328_;
  __vec16_f int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i334_;
  __vec16_f div__add__mul__L_load_2e_i338_;
  __vec16_f mul_k_load_k_load4_2e_i339_;
  __vec16_f mul_k2_load_k_load5_2e_i340_;
  __vec16_f calltmp_2e_i_2e_i355_;
  __vec16_f mul_w_load_mul__calltmp16_2e_i358_;
  __vec16_f v1_2e_i429_;

  aligned_end_ = ((uint32_t )(((uint32_t )count_) - ((uint32_t )(((int32_t )(((int32_t )count_) % ((int32_t )16u)))))));
  if ((((int32_t )aligned_end_) > ((int32_t )0u))) {
    goto foreach_full_body_2e_lr_2e_ph_label;
  } else {
    counter_2e_1_2e_lcssa___PHI = 0u;   /* for PHI node */
    goto partial_inner_all_outer_label;
  }

foreach_full_body_2e_lr_2e_ph_label: {
  Sa_load_ptr2int_2void_ = ((uint8_t *)Sa_);
  Xa_load_ptr2int_2void_ = ((uint8_t *)Xa_);
  Ta_load_ptr2int_2void_ = ((uint8_t *)Ta_);
  ra_load_ptr2int_2void_ = ((uint8_t *)ra_);
  va_load_ptr2int_2void_ = ((uint8_t *)va_);
  result_load_ptr2int_2void_ = ((uint8_t *)result_);
  counter_2e_1435___PHI = 0u;   /* for PHI node */
  goto foreach_full_body_label;

}
  do {     /* Syntactic loop 'foreach_full_body' to make GCC happy */
foreach_full_body_label: {
  counter_2e_1435_ = counter_2e_1435___PHI;
  tmp__23_ = ((int64_t )(int32_t )(counter_2e_1435_ << 2u));
  ptr_masked_load363_ = __load<4>((((__vec16_f (*))((&Sa_load_ptr2int_2void_[((int64_t )tmp__23_)])))));
  ptr365_masked_load367_ = __load<4>((((__vec16_f (*))((&Xa_load_ptr2int_2void_[((int64_t )tmp__23_)])))));
  ptr370_masked_load372_ = __load<4>((((__vec16_f (*))((&Ta_load_ptr2int_2void_[((int64_t )tmp__23_)])))));
  ptr375_masked_load377_ = __load<4>((((__vec16_f (*))((&ra_load_ptr2int_2void_[((int64_t )tmp__23_)])))));
  ptr380_masked_load382_ = __load<4>((((__vec16_f (*))((&va_load_ptr2int_2void_[((int64_t )tmp__23_)])))));
  calltmp_2e_i_ = __log_varying_float((__div(ptr_masked_load363_, ptr365_masked_load367_)));
  calltmp_2e_i254_ = __sqrt_varying_float(ptr370_masked_load372_);
  div_add_calltmp_mul_add_r_load_mul_mul_v_load_v_load54__T_load_mul_v_load55_calltmp59_ = __div((__add(calltmp_2e_i_, (__mul(ptr370_masked_load372_, (__add(ptr375_masked_load377_, (__mul((__mul(ptr380_masked_load382_, ptr380_masked_load382_)), __smear_float<__vec16_f>(0x1p-1))))))))), (__mul(ptr380_masked_load382_, calltmp_2e_i254_)));
  calltmp_2e_i255_ = __sqrt_varying_float(ptr370_masked_load372_);
  sub_d1_load_mul_v_load60_calltmp64_ = __sub(div_add_calltmp_mul_add_r_load_mul_mul_v_load_v_load54__T_load_mul_v_load55_calltmp59_, (__mul(ptr380_masked_load382_, calltmp_2e_i255_)));
  int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i_ = (__cast_bits(__vec16_f (), (__and(((__cast_bits(__vec16_i32 (), div_add_calltmp_mul_add_r_load_mul_mul_v_load_v_load54__T_load_mul_v_load55_calltmp59_))), __smear_i32<__vec16_i32>(2147483647u)))));
  div__add__mul__L_load_2e_i_ = __div(__smear_float<__vec16_f>(0x1p+0), (__add((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i_, __smear_float<__vec16_f>(0x1.da6712p-3))), __smear_float<__vec16_f>(0x1p+0))));
  mul_k_load_k_load4_2e_i_ = __mul(div__add__mul__L_load_2e_i_, div__add__mul__L_load_2e_i_);
  mul_k2_load_k_load5_2e_i_ = __mul(div__add__mul__L_load_2e_i_, mul_k_load_k_load4_2e_i_);
  calltmp_2e_i_2e_i_ = __exp_varying_float((__mul((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i_, (__sub(__setzero_float<__vec16_f>(), int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i_)))), __smear_float<__vec16_f>(0x1p-1))));
  mul_w_load_mul__calltmp16_2e_i_ = __mul((__mul(calltmp_2e_i_2e_i_, __smear_float<__vec16_f>(0x1.988454p-2))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i_, mul_k2_load_k_load5_2e_i_)), __smear_float<__vec16_f>(0x1.548cdep+0))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i_, mul_k_load_k_load4_2e_i_)), __smear_float<__vec16_f>(-0x1.d23dd4p+0))), (__add((__sub((__mul(div__add__mul__L_load_2e_i_, __smear_float<__vec16_f>(0x1.470bf4p-2))), (__mul(mul_k_load_k_load4_2e_i_, __smear_float<__vec16_f>(0x1.6d1f0ep-2))))), (__mul(mul_k2_load_k_load5_2e_i_, __smear_float<__vec16_f>(0x1.c80efp+0))))))))));
  v1_2e_i_ = __select((__greater_than_float(div_add_calltmp_mul_add_r_load_mul_mul_v_load_v_load54__T_load_mul_v_load55_calltmp59_, __setzero_float<__vec16_f>())), (__sub(__smear_float<__vec16_f>(0x1p+0), mul_w_load_mul__calltmp16_2e_i_)), mul_w_load_mul__calltmp16_2e_i_);
  calltmp_2e_i256_ = __exp_varying_float((__mul(ptr370_masked_load372_, (__sub(__setzero_float<__vec16_f>(), ptr375_masked_load377_)))));
  int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i262_ = (__cast_bits(__vec16_f (), (__and(((__cast_bits(__vec16_i32 (), sub_d1_load_mul_v_load60_calltmp64_))), __smear_i32<__vec16_i32>(2147483647u)))));
  div__add__mul__L_load_2e_i266_ = __div(__smear_float<__vec16_f>(0x1p+0), (__add((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i262_, __smear_float<__vec16_f>(0x1.da6712p-3))), __smear_float<__vec16_f>(0x1p+0))));
  mul_k_load_k_load4_2e_i267_ = __mul(div__add__mul__L_load_2e_i266_, div__add__mul__L_load_2e_i266_);
  mul_k2_load_k_load5_2e_i268_ = __mul(div__add__mul__L_load_2e_i266_, mul_k_load_k_load4_2e_i267_);
  calltmp_2e_i_2e_i283_ = __exp_varying_float((__mul((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i262_, (__sub(__setzero_float<__vec16_f>(), int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i262_)))), __smear_float<__vec16_f>(0x1p-1))));
  mul_w_load_mul__calltmp16_2e_i286_ = __mul((__mul(calltmp_2e_i_2e_i283_, __smear_float<__vec16_f>(0x1.988454p-2))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i267_, mul_k2_load_k_load5_2e_i268_)), __smear_float<__vec16_f>(0x1.548cdep+0))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i267_, mul_k_load_k_load4_2e_i267_)), __smear_float<__vec16_f>(-0x1.d23dd4p+0))), (__add((__sub((__mul(div__add__mul__L_load_2e_i266_, __smear_float<__vec16_f>(0x1.470bf4p-2))), (__mul(mul_k_load_k_load4_2e_i267_, __smear_float<__vec16_f>(0x1.6d1f0ep-2))))), (__mul(mul_k2_load_k_load5_2e_i268_, __smear_float<__vec16_f>(0x1.c80efp+0))))))))));
  v1_2e_i433_ = __select((__greater_than_float(sub_d1_load_mul_v_load60_calltmp64_, __setzero_float<__vec16_f>())), (__sub(__smear_float<__vec16_f>(0x1p+0), mul_w_load_mul__calltmp16_2e_i286_)), mul_w_load_mul__calltmp16_2e_i286_);
  __store<4>((((__vec16_f (*))((&result_load_ptr2int_2void_[((int64_t )tmp__23_)])))), (__sub((__mul(ptr_masked_load363_, v1_2e_i_)), (__mul((__mul(ptr365_masked_load367_, calltmp_2e_i256_)), v1_2e_i433_)))));
  new_counter_ = ((uint32_t )(((uint32_t )counter_2e_1435_) + ((uint32_t )16u)));
  if ((((int32_t )new_counter_) < ((int32_t )aligned_end_))) {
    counter_2e_1435___PHI = new_counter_;   /* for PHI node */
    goto foreach_full_body_label;
  } else {
    counter_2e_1_2e_lcssa___PHI = new_counter_;   /* for PHI node */
    goto partial_inner_all_outer_label;
  }

}
  } while (1); /* end of syntactic loop 'foreach_full_body' */
foreach_reset_label: {
  return;
}
partial_inner_all_outer_label: {
  counter_2e_1_2e_lcssa_ = counter_2e_1_2e_lcssa___PHI;
  if ((((int32_t )counter_2e_1_2e_lcssa_) < ((int32_t )count_))) {
    goto partial_inner_only_label;
  } else {
    goto foreach_reset_label;
  }

}
partial_inner_only_label: {
  counter_2e_1_2e_lcssa_smear_ = __smear_i32<__vec16_i32>(counter_2e_1_2e_lcssa_);
  count_smear_ = __smear_i32<__vec16_i32>(count_);
  cmp95_ = __signed_less_than_i32((__add(counter_2e_1_2e_lcssa_smear_, __load<64>((const __vec16_i32  *)(VectorConstant4)))), count_smear_);
  tmp__24_ = ((int64_t )(int32_t )(counter_2e_1_2e_lcssa_ << 2u));
  ptr392_masked_load_ = __masked_load_float(((&(((uint8_t *)Sa_))[((int64_t )tmp__24_)])), cmp95_);
  ptr398_masked_load_ = __masked_load_float(((&(((uint8_t *)Xa_))[((int64_t )tmp__24_)])), cmp95_);
  ptr404_masked_load_ = __masked_load_float(((&(((uint8_t *)Ta_))[((int64_t )tmp__24_)])), cmp95_);
  ptr410_masked_load_ = __masked_load_float(((&(((uint8_t *)ra_))[((int64_t )tmp__24_)])), cmp95_);
  ptr416_masked_load_ = __masked_load_float(((&(((uint8_t *)va_))[((int64_t )tmp__24_)])), cmp95_);
  calltmp_2e_i291_ = __log_varying_float((__div(ptr392_masked_load_, ptr398_masked_load_)));
  calltmp_2e_i292_ = __sqrt_varying_float(ptr404_masked_load_);
  div_add_calltmp140_mul_add_r_load141_mul_mul_v_load142_v_load143__T_load144_mul_v_load145_calltmp149_ = __div((__add(calltmp_2e_i291_, (__mul(ptr404_masked_load_, (__add(ptr410_masked_load_, (__mul((__mul(ptr416_masked_load_, ptr416_masked_load_)), __smear_float<__vec16_f>(0x1p-1))))))))), (__mul(ptr416_masked_load_, calltmp_2e_i292_)));
  calltmp_2e_i293_ = __sqrt_varying_float(ptr404_masked_load_);
  sub_d1_load151_mul_v_load152_calltmp156_ = __sub(div_add_calltmp140_mul_add_r_load141_mul_mul_v_load142_v_load143__T_load144_mul_v_load145_calltmp149_, (__mul(ptr416_masked_load_, calltmp_2e_i293_)));
  int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i299_ = (__cast_bits(__vec16_f (), (__and(((__cast_bits(__vec16_i32 (), div_add_calltmp140_mul_add_r_load141_mul_mul_v_load142_v_load143__T_load144_mul_v_load145_calltmp149_))), __smear_i32<__vec16_i32>(2147483647u)))));
  div__add__mul__L_load_2e_i303_ = __div(__smear_float<__vec16_f>(0x1p+0), (__add((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i299_, __smear_float<__vec16_f>(0x1.da6712p-3))), __smear_float<__vec16_f>(0x1p+0))));
  mul_k_load_k_load4_2e_i304_ = __mul(div__add__mul__L_load_2e_i303_, div__add__mul__L_load_2e_i303_);
  mul_k2_load_k_load5_2e_i305_ = __mul(div__add__mul__L_load_2e_i303_, mul_k_load_k_load4_2e_i304_);
  calltmp_2e_i_2e_i320_ = __exp_varying_float((__mul((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i299_, (__sub(__setzero_float<__vec16_f>(), int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i299_)))), __smear_float<__vec16_f>(0x1p-1))));
  mul_w_load_mul__calltmp16_2e_i323_ = __mul((__mul(calltmp_2e_i_2e_i320_, __smear_float<__vec16_f>(0x1.988454p-2))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i304_, mul_k2_load_k_load5_2e_i305_)), __smear_float<__vec16_f>(0x1.548cdep+0))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i304_, mul_k_load_k_load4_2e_i304_)), __smear_float<__vec16_f>(-0x1.d23dd4p+0))), (__add((__sub((__mul(div__add__mul__L_load_2e_i303_, __smear_float<__vec16_f>(0x1.470bf4p-2))), (__mul(mul_k_load_k_load4_2e_i304_, __smear_float<__vec16_f>(0x1.6d1f0ep-2))))), (__mul(mul_k2_load_k_load5_2e_i305_, __smear_float<__vec16_f>(0x1.c80efp+0))))))))));
  v1_2e_i431_ = __select((__greater_than_float(div_add_calltmp140_mul_add_r_load141_mul_mul_v_load142_v_load143__T_load144_mul_v_load145_calltmp149_, __setzero_float<__vec16_f>())), (__sub(__smear_float<__vec16_f>(0x1p+0), mul_w_load_mul__calltmp16_2e_i323_)), mul_w_load_mul__calltmp16_2e_i323_);
  calltmp_2e_i328_ = __exp_varying_float((__mul(ptr404_masked_load_, (__sub(__setzero_float<__vec16_f>(), ptr410_masked_load_)))));
  int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i334_ = (__cast_bits(__vec16_f (), (__and(((__cast_bits(__vec16_i32 (), sub_d1_load151_mul_v_load152_calltmp156_))), __smear_i32<__vec16_i32>(2147483647u)))));
  div__add__mul__L_load_2e_i338_ = __div(__smear_float<__vec16_f>(0x1p+0), (__add((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i334_, __smear_float<__vec16_f>(0x1.da6712p-3))), __smear_float<__vec16_f>(0x1p+0))));
  mul_k_load_k_load4_2e_i339_ = __mul(div__add__mul__L_load_2e_i338_, div__add__mul__L_load_2e_i338_);
  mul_k2_load_k_load5_2e_i340_ = __mul(div__add__mul__L_load_2e_i338_, mul_k_load_k_load4_2e_i339_);
  calltmp_2e_i_2e_i355_ = __exp_varying_float((__mul((__mul(int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i334_, (__sub(__setzero_float<__vec16_f>(), int_to_float_bitcast_2e_i_2e_i_2e_i_2e_i334_)))), __smear_float<__vec16_f>(0x1p-1))));
  mul_w_load_mul__calltmp16_2e_i358_ = __mul((__mul(calltmp_2e_i_2e_i355_, __smear_float<__vec16_f>(0x1.988454p-2))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i339_, mul_k2_load_k_load5_2e_i340_)), __smear_float<__vec16_f>(0x1.548cdep+0))), (__add((__mul((__mul(mul_k_load_k_load4_2e_i339_, mul_k_load_k_load4_2e_i339_)), __smear_float<__vec16_f>(-0x1.d23dd4p+0))), (__add((__sub((__mul(div__add__mul__L_load_2e_i338_, __smear_float<__vec16_f>(0x1.470bf4p-2))), (__mul(mul_k_load_k_load4_2e_i339_, __smear_float<__vec16_f>(0x1.6d1f0ep-2))))), (__mul(mul_k2_load_k_load5_2e_i340_, __smear_float<__vec16_f>(0x1.c80efp+0))))))))));
  v1_2e_i429_ = __select((__greater_than_float(sub_d1_load151_mul_v_load152_calltmp156_, __setzero_float<__vec16_f>())), (__sub(__smear_float<__vec16_f>(0x1p+0), mul_w_load_mul__calltmp16_2e_i358_)), mul_w_load_mul__calltmp16_2e_i358_);
  __masked_store_float((((__vec16_f (*))((&(((uint8_t *)result_))[((int64_t )tmp__24_)])))), (__sub((__mul(ptr392_masked_load_, v1_2e_i431_)), (__mul((__mul(ptr398_masked_load_, calltmp_2e_i328_)), v1_2e_i429_)))), cmp95_);
  goto foreach_reset_label;

}
}


static const int32_t __attribute__ ((aligned(64))) VectorConstant5[] = { 0u, 1u, 2u, 3u, 4u, 5u, 6u, 7u, 8u, 9u, 10u, 11u, 12u, 13u, 14u, 15u,  };

void binomial_put_ispc(float *Sa_, float *Xa_, float *Ta_, float *ra_, float *va_, float *result_, uint32_t count_) {
  l_array_1 V_2e_i_;    /* Address-exposed local */
  uint32_t aligned_end_;
  uint8_t *Sa_load_ptr2int_2void_;
  uint8_t *Xa_load_ptr2int_2void_;
  uint8_t *Ta_load_ptr2int_2void_;
  uint8_t *ra_load_ptr2int_2void_;
  uint8_t *va_load_ptr2int_2void_;
  uint8_t *tmp__25_;
  __vec16_f (*V_offset59_2e_i_);
  uint8_t *result_load_ptr2int_2void_;
  uint32_t counter_2e_1324_;
  uint32_t counter_2e_1324___PHI;
  uint64_t tmp__26_;
  __vec16_f ptr_masked_load256_;
  __vec16_f ptr258_masked_load260_;
  __vec16_f ptr263_masked_load265_;
  __vec16_f ptr268_masked_load270_;
  __vec16_f ptr273_masked_load275_;
  __vec16_f div_T_load__2e_i_;
  __vec16_f calltmp_2e_i_2e_i_;
  __vec16_f calltmp_2e_i1_2e_i_;
  __vec16_f div__u_load_2e_i_;
  __vec16_f calltmp_2e_i2_2e_i_;
  __vec16_f sub_u_load15_d_load16_2e_i_;
  uint64_t indvars_2e_iv333_;
  uint64_t indvars_2e_iv333___PHI;
  __vec16_f sub_mul__j_load21__to_float_2e_i_smear_;
  __vec16_f calltmp_2e_i3_2e_i_;
  __vec16_f calltmp_2e_i4_2e_i_;
  uint64_t indvars_2e_iv_2e_next334_;
  __vec16_f div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i_;
  __vec16_f sub__Pu_load_2e_i_;
  uint32_t indvars_2e_iv341_;
  uint32_t indvars_2e_iv341___PHI;
  uint64_t indvars_2e_iv339_;
  uint64_t indvars_2e_iv339___PHI;
  __vec16_f (*V_offset48_2e_i_);
  __vec16_f V_offset50_load_2e_i_;
  uint64_t indvars_2e_iv_2e_next340_;
  __vec16_f V_offset54_load_2e_i_;
  uint32_t indvars_2e_iv_2e_next342_;
  __vec16_f V_offset59_load_2e_i_;
  uint32_t new_counter_;
  __vec16_f div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i211_;
  __vec16_f sub__Pu_load_2e_i239_;
  uint64_t indvars_2e_iv327_;
  uint64_t indvars_2e_iv327___PHI;
  __vec16_f sub_mul__j_load21__to_float_2e_i217_smear_;
  __vec16_f calltmp_2e_i3_2e_i220_;
  __vec16_f calltmp_2e_i4_2e_i225_;
  uint64_t indvars_2e_iv_2e_next328_;
  uint32_t indvars_2e_iv325_;
  uint32_t indvars_2e_iv325___PHI;
  uint64_t indvars_2e_iv_;
  uint64_t indvars_2e_iv___PHI;
  __vec16_f (*V_offset48_2e_i238_);
  __vec16_f V_offset50_load_2e_i242_;
  uint64_t indvars_2e_iv_2e_next_;
  __vec16_f V_offset54_load_2e_i247_;
  uint32_t indvars_2e_iv_2e_next326_;
  __vec16_f V_offset59_load_2e_i232_;
  uint32_t counter_2e_1_2e_lcssa_;
  uint32_t counter_2e_1_2e_lcssa___PHI;
  __vec16_i32 counter_2e_1_2e_lcssa_smear_;
  __vec16_i32 count_smear_;
  __vec16_i1 cmp70_;
  uint64_t tmp__27_;
  __vec16_f ptr282_masked_load_;
  __vec16_f ptr288_masked_load_;
  __vec16_f ptr294_masked_load_;
  __vec16_f ptr300_masked_load_;
  __vec16_f ptr306_masked_load_;
  uint8_t *tmp__28_;
  __vec16_f div_T_load__2e_i202_;
  __vec16_f calltmp_2e_i_2e_i203_;
  __vec16_f calltmp_2e_i1_2e_i205_;
  __vec16_f div__u_load_2e_i206_;
  __vec16_f calltmp_2e_i2_2e_i208_;
  __vec16_f sub_u_load15_d_load16_2e_i210_;

  aligned_end_ = ((uint32_t )(((uint32_t )count_) - ((uint32_t )(((int32_t )(((int32_t )count_) % ((int32_t )16u)))))));
  if ((((int32_t )aligned_end_) > ((int32_t )0u))) {
    goto foreach_full_body_2e_lr_2e_ph_label;
  } else {
    counter_2e_1_2e_lcssa___PHI = 0u;   /* for PHI node */
    goto partial_inner_all_outer_label;
  }

foreach_full_body_2e_lr_2e_ph_label: {
  Sa_load_ptr2int_2void_ = ((uint8_t *)Sa_);
  Xa_load_ptr2int_2void_ = ((uint8_t *)Xa_);
  Ta_load_ptr2int_2void_ = ((uint8_t *)Ta_);
  ra_load_ptr2int_2void_ = ((uint8_t *)ra_);
  va_load_ptr2int_2void_ = ((uint8_t *)va_);
  tmp__25_ = ((uint8_t *)(&V_2e_i_));
  V_offset59_2e_i_ = (&V_2e_i_.array[((int64_t )0ull)]);
  result_load_ptr2int_2void_ = ((uint8_t *)result_);
  counter_2e_1324___PHI = 0u;   /* for PHI node */
  goto foreach_full_body_label;

}
  do {     /* Syntactic loop 'foreach_full_body' to make GCC happy */
foreach_full_body_label: {
  counter_2e_1324_ = counter_2e_1324___PHI;
  tmp__26_ = ((int64_t )(int32_t )(counter_2e_1324_ << 2u));
  ptr_masked_load256_ = __load<4>((((__vec16_f (*))((&Sa_load_ptr2int_2void_[((int64_t )tmp__26_)])))));
  ptr258_masked_load260_ = __load<4>((((__vec16_f (*))((&Xa_load_ptr2int_2void_[((int64_t )tmp__26_)])))));
  ptr263_masked_load265_ = __load<4>((((__vec16_f (*))((&Ta_load_ptr2int_2void_[((int64_t )tmp__26_)])))));
  ptr268_masked_load270_ = __load<4>((((__vec16_f (*))((&ra_load_ptr2int_2void_[((int64_t )tmp__26_)])))));
  ptr273_masked_load275_ = __load<4>((((__vec16_f (*))((&va_load_ptr2int_2void_[((int64_t )tmp__26_)])))));
  div_T_load__2e_i_ = __div(ptr263_masked_load265_, __smear_float<__vec16_f>(0x1p+6));
  calltmp_2e_i_2e_i_ = __sqrt_varying_float(div_T_load__2e_i_);
  calltmp_2e_i1_2e_i_ = __exp_varying_float((__mul(ptr273_masked_load275_, calltmp_2e_i_2e_i_)));
  div__u_load_2e_i_ = __div(__smear_float<__vec16_f>(0x1p+0), calltmp_2e_i1_2e_i_);
  calltmp_2e_i2_2e_i_ = __exp_varying_float((__mul(ptr268_masked_load270_, div_T_load__2e_i_)));
  sub_u_load15_d_load16_2e_i_ = __sub(calltmp_2e_i1_2e_i_, div__u_load_2e_i_);
  indvars_2e_iv333___PHI = 0ull;   /* for PHI node */
  goto for_loop_2e_i_label;

}
  do {     /* Syntactic loop 'for_loop.i' to make GCC happy */
for_loop_2e_i_label: {
  indvars_2e_iv333_ = indvars_2e_iv333___PHI;
  sub_mul__j_load21__to_float_2e_i_smear_ = __smear_float<__vec16_f>((((float )(int32_t )(((uint32_t )(((uint64_t )(((uint64_t )(indvars_2e_iv333_ << 1ull)) + ((uint64_t )4294967232ull)))))))));
  calltmp_2e_i3_2e_i_ = __pow_varying_float(calltmp_2e_i1_2e_i_, sub_mul__j_load21__to_float_2e_i_smear_);
  calltmp_2e_i4_2e_i_ = __max_varying_float(__setzero_float<__vec16_f>(), (__sub(ptr258_masked_load260_, (__mul(ptr_masked_load256_, calltmp_2e_i3_2e_i_)))));
  __store<64>(((&V_2e_i_.array[((int64_t )indvars_2e_iv333_)])), calltmp_2e_i4_2e_i_);
  indvars_2e_iv_2e_next334_ = ((uint64_t )(((uint64_t )indvars_2e_iv333_) + ((uint64_t )1ull)));
  if (((((uint32_t )indvars_2e_iv_2e_next334_)) == 64u)) {
    goto for_test30_2e_i_2e_loopexit_label;
  } else {
    indvars_2e_iv333___PHI = indvars_2e_iv_2e_next334_;   /* for PHI node */
    goto for_loop_2e_i_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop.i' */
for_test30_2e_i_2e_loopexit_label: {
  div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i_ = __div((__sub(calltmp_2e_i2_2e_i_, div__u_load_2e_i_)), sub_u_load15_d_load16_2e_i_);
  sub__Pu_load_2e_i_ = __sub(__smear_float<__vec16_f>(0x1p+0), div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i_);
  indvars_2e_iv341___PHI = 63u;   /* for PHI node */
  goto for_test39_2e_i_2e_preheader_label;

}
  do {     /* Syntactic loop 'for_test39.i.preheader' to make GCC happy */
for_test39_2e_i_2e_preheader_label: {
  indvars_2e_iv341_ = indvars_2e_iv341___PHI;
  if ((((int32_t )indvars_2e_iv341_) > ((int32_t )0u))) {
    indvars_2e_iv339___PHI = 0ull;   /* for PHI node */
    goto for_loop41_2e_i_label;
  } else {
    goto for_exit42_2e_i_label;
  }

}
  do {     /* Syntactic loop 'for_loop41.i' to make GCC happy */
for_loop41_2e_i_label: {
  indvars_2e_iv339_ = indvars_2e_iv339___PHI;
  V_offset48_2e_i_ = (&V_2e_i_.array[((int64_t )indvars_2e_iv339_)]);
  V_offset50_load_2e_i_ = __load<64>(V_offset48_2e_i_);
  indvars_2e_iv_2e_next340_ = ((uint64_t )(((uint64_t )indvars_2e_iv339_) + ((uint64_t )1ull)));
  V_offset54_load_2e_i_ = __load<64>(((&V_2e_i_.array[((int64_t )indvars_2e_iv_2e_next340_)])));
  __store<64>(V_offset48_2e_i_, (__div((__add((__mul(sub__Pu_load_2e_i_, V_offset50_load_2e_i_)), (__mul(div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i_, V_offset54_load_2e_i_)))), calltmp_2e_i2_2e_i_)));
  if (((((uint32_t )indvars_2e_iv_2e_next340_)) == indvars_2e_iv341_)) {
    goto for_exit42_2e_i_label;
  } else {
    indvars_2e_iv339___PHI = indvars_2e_iv_2e_next340_;   /* for PHI node */
    goto for_loop41_2e_i_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop41.i' */
for_exit42_2e_i_label: {
  indvars_2e_iv_2e_next342_ = ((uint32_t )(((uint32_t )indvars_2e_iv341_) + ((uint32_t )4294967295u)));
  if ((((int32_t )indvars_2e_iv_2e_next342_) > ((int32_t )4294967295u))) {
    indvars_2e_iv341___PHI = indvars_2e_iv_2e_next342_;   /* for PHI node */
    goto for_test39_2e_i_2e_preheader_label;
  } else {
    goto binomial_put___vyfvyfvyfvyfvyf_2e_exit_label;
  }

}
  } while (1); /* end of syntactic loop 'for_test39.i.preheader' */
binomial_put___vyfvyfvyfvyfvyf_2e_exit_label: {
  V_offset59_load_2e_i_ = __load<64>(V_offset59_2e_i_);
  __store<4>((((__vec16_f (*))((&result_load_ptr2int_2void_[((int64_t )tmp__26_)])))), V_offset59_load_2e_i_);
  new_counter_ = ((uint32_t )(((uint32_t )counter_2e_1324_) + ((uint32_t )16u)));
  if ((((int32_t )new_counter_) < ((int32_t )aligned_end_))) {
    counter_2e_1324___PHI = new_counter_;   /* for PHI node */
    goto foreach_full_body_label;
  } else {
    counter_2e_1_2e_lcssa___PHI = new_counter_;   /* for PHI node */
    goto partial_inner_all_outer_label;
  }

}
  } while (1); /* end of syntactic loop 'foreach_full_body' */
for_test30_2e_i230_2e_preheader_label: {
  div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i211_ = __div((__sub(calltmp_2e_i2_2e_i208_, div__u_load_2e_i206_)), sub_u_load15_d_load16_2e_i210_);
  sub__Pu_load_2e_i239_ = __sub(__smear_float<__vec16_f>(0x1p+0), div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i211_);
  indvars_2e_iv325___PHI = 63u;   /* for PHI node */
  goto for_test39_2e_i236_2e_preheader_label;

}
  do {     /* Syntactic loop 'for_loop.i227' to make GCC happy */
for_loop_2e_i227_label: {
  indvars_2e_iv327_ = indvars_2e_iv327___PHI;
  sub_mul__j_load21__to_float_2e_i217_smear_ = __smear_float<__vec16_f>((((float )(int32_t )(((uint32_t )(((uint64_t )(((uint64_t )(indvars_2e_iv327_ << 1ull)) + ((uint64_t )4294967232ull)))))))));
  calltmp_2e_i3_2e_i220_ = __pow_varying_float(calltmp_2e_i1_2e_i205_, sub_mul__j_load21__to_float_2e_i217_smear_);
  calltmp_2e_i4_2e_i225_ = __max_varying_float(__setzero_float<__vec16_f>(), (__sub(ptr288_masked_load_, (__mul(ptr282_masked_load_, calltmp_2e_i3_2e_i220_)))));
  __store<64>(((&V_2e_i_.array[((int64_t )indvars_2e_iv327_)])), calltmp_2e_i4_2e_i225_);
  indvars_2e_iv_2e_next328_ = ((uint64_t )(((uint64_t )indvars_2e_iv327_) + ((uint64_t )1ull)));
  if (((((uint32_t )indvars_2e_iv_2e_next328_)) == 64u)) {
    goto for_test30_2e_i230_2e_preheader_label;
  } else {
    indvars_2e_iv327___PHI = indvars_2e_iv_2e_next328_;   /* for PHI node */
    goto for_loop_2e_i227_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop.i227' */
  do {     /* Syntactic loop 'for_test39.i236.preheader' to make GCC happy */
for_test39_2e_i236_2e_preheader_label: {
  indvars_2e_iv325_ = indvars_2e_iv325___PHI;
  if ((((int32_t )indvars_2e_iv325_) > ((int32_t )0u))) {
    indvars_2e_iv___PHI = 0ull;   /* for PHI node */
    goto for_loop41_2e_i252_label;
  } else {
    goto for_exit42_2e_i254_label;
  }

}
  do {     /* Syntactic loop 'for_loop41.i252' to make GCC happy */
for_loop41_2e_i252_label: {
  indvars_2e_iv_ = indvars_2e_iv___PHI;
  V_offset48_2e_i238_ = (&V_2e_i_.array[((int64_t )indvars_2e_iv_)]);
  V_offset50_load_2e_i242_ = __load<64>(V_offset48_2e_i238_);
  indvars_2e_iv_2e_next_ = ((uint64_t )(((uint64_t )indvars_2e_iv_) + ((uint64_t )1ull)));
  V_offset54_load_2e_i247_ = __load<64>(((&V_2e_i_.array[((int64_t )indvars_2e_iv_2e_next_)])));
  __store<64>(V_offset48_2e_i238_, (__div((__add((__mul(sub__Pu_load_2e_i239_, V_offset50_load_2e_i242_)), (__mul(div_sub_disc_load_d_load_sub_u_load15_d_load16_2e_i211_, V_offset54_load_2e_i247_)))), calltmp_2e_i2_2e_i208_)));
  if (((((uint32_t )indvars_2e_iv_2e_next_)) == indvars_2e_iv325_)) {
    goto for_exit42_2e_i254_label;
  } else {
    indvars_2e_iv___PHI = indvars_2e_iv_2e_next_;   /* for PHI node */
    goto for_loop41_2e_i252_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop41.i252' */
for_exit42_2e_i254_label: {
  indvars_2e_iv_2e_next326_ = ((uint32_t )(((uint32_t )indvars_2e_iv325_) + ((uint32_t )4294967295u)));
  if ((((int32_t )indvars_2e_iv_2e_next326_) > ((int32_t )4294967295u))) {
    indvars_2e_iv325___PHI = indvars_2e_iv_2e_next326_;   /* for PHI node */
    goto for_test39_2e_i236_2e_preheader_label;
  } else {
    goto binomial_put___vyfvyfvyfvyfvyf_2e_exit255_label;
  }

}
  } while (1); /* end of syntactic loop 'for_test39.i236.preheader' */
binomial_put___vyfvyfvyfvyfvyf_2e_exit255_label: {
  V_offset59_load_2e_i232_ = __load<64>(((&V_2e_i_.array[((int64_t )0ull)])));
  __masked_store_float((((__vec16_f (*))((&(((uint8_t *)result_))[((int64_t )tmp__27_)])))), V_offset59_load_2e_i232_, cmp70_);
  goto foreach_reset_label;

}
foreach_reset_label: {
  return;
}
partial_inner_all_outer_label: {
  counter_2e_1_2e_lcssa_ = counter_2e_1_2e_lcssa___PHI;
  if ((((int32_t )counter_2e_1_2e_lcssa_) < ((int32_t )count_))) {
    goto partial_inner_only_label;
  } else {
    goto foreach_reset_label;
  }

}
partial_inner_only_label: {
  counter_2e_1_2e_lcssa_smear_ = __smear_i32<__vec16_i32>(counter_2e_1_2e_lcssa_);
  count_smear_ = __smear_i32<__vec16_i32>(count_);
  cmp70_ = __signed_less_than_i32((__add(counter_2e_1_2e_lcssa_smear_, __load<64>((const __vec16_i32  *)(VectorConstant5)))), count_smear_);
  tmp__27_ = ((int64_t )(int32_t )(counter_2e_1_2e_lcssa_ << 2u));
  ptr282_masked_load_ = __masked_load_float(((&(((uint8_t *)Sa_))[((int64_t )tmp__27_)])), cmp70_);
  ptr288_masked_load_ = __masked_load_float(((&(((uint8_t *)Xa_))[((int64_t )tmp__27_)])), cmp70_);
  ptr294_masked_load_ = __masked_load_float(((&(((uint8_t *)Ta_))[((int64_t )tmp__27_)])), cmp70_);
  ptr300_masked_load_ = __masked_load_float(((&(((uint8_t *)ra_))[((int64_t )tmp__27_)])), cmp70_);
  ptr306_masked_load_ = __masked_load_float(((&(((uint8_t *)va_))[((int64_t )tmp__27_)])), cmp70_);
  tmp__28_ = ((uint8_t *)(&V_2e_i_));
  div_T_load__2e_i202_ = __div(ptr294_masked_load_, __smear_float<__vec16_f>(0x1p+6));
  calltmp_2e_i_2e_i203_ = __sqrt_varying_float(div_T_load__2e_i202_);
  calltmp_2e_i1_2e_i205_ = __exp_varying_float((__mul(ptr306_masked_load_, calltmp_2e_i_2e_i203_)));
  div__u_load_2e_i206_ = __div(__smear_float<__vec16_f>(0x1p+0), calltmp_2e_i1_2e_i205_);
  calltmp_2e_i2_2e_i208_ = __exp_varying_float((__mul(ptr300_masked_load_, div_T_load__2e_i202_)));
  sub_u_load15_d_load16_2e_i210_ = __sub(calltmp_2e_i1_2e_i205_, div__u_load_2e_i206_);
  indvars_2e_iv327___PHI = 0ull;   /* for PHI node */
  goto for_loop_2e_i227_label;

}
}



void binomial_put_ispc_tasks(float *Sa_, float *Xa_, float *Ta_, float *ra_, float *va_, float *result_, uint32_t count_) {
  uint8_t *launch_group_handle_;    /* Address-exposed local */
  uint32_t calltmp_2e_i_;
  uint8_t *args_ptr_;
  uint8_t *launch_group_handle_load_;

  *(&launch_group_handle_) = ((uint8_t *)/*NULL*/0);
  calltmp_2e_i_ = __max_uniform_int32(64u, (((int32_t )(((int32_t )count_) / ((int32_t )16384u)))));
  args_ptr_ = ISPCAlloc((&launch_group_handle_), 56ull, 64u);
  *(((float **)args_ptr_)) = Sa_;
  *(((float **)((&args_ptr_[((int64_t )8ull)])))) = Xa_;
  *(((float **)((&args_ptr_[((int64_t )16ull)])))) = Ta_;
  *(((float **)((&args_ptr_[((int64_t )24ull)])))) = ra_;
  *(((float **)((&args_ptr_[((int64_t )32ull)])))) = va_;
  *(((float **)((&args_ptr_[((int64_t )40ull)])))) = result_;
  *(((uint32_t *)((&args_ptr_[((int64_t )48ull)])))) = count_;
  __store<2>((((__vec16_i1 (*))((&args_ptr_[((int64_t )52ull)])))), __smear_i1<__vec16_i1>(1));
  ISPCLaunch((&launch_group_handle_), ((uint8_t *)binomial_task___un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_un_3C_unf_3E_uni), args_ptr_, calltmp_2e_i_);
  launch_group_handle_load_ = *(&launch_group_handle_);
  if ((launch_group_handle_load_ == ((uint8_t *)/*NULL*/0))) {
    goto post_sync_label;
  } else {
    goto call_sync_label;
  }

call_sync_label: {
  ISPCSync(launch_group_handle_load_);
  *(&launch_group_handle_) = ((uint8_t *)/*NULL*/0);
  goto post_sync_label;

}
post_sync_label: {
  return;
}
}

